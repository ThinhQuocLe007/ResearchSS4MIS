{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from skimage.measure import label\n",
    "\n",
    "# torch \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Module \n",
    "from dataset.basedataset import ACDCDataset\n",
    "from dataset.utils import RandomGenerator\n",
    "from utils.losses import DiceLoss\n",
    "from networks.net_factory import BCP_net\n",
    "from utils import masks\n",
    "from utils.valid2d import test_single_volume, test_single_volume_mean\n",
    "from networks.utils import save_net_opt, load_net, load_net_opt\n",
    "from networks.utils import update_model_ema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param \n",
    "from utils.params import params\n",
    "args = params() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ACDC_LargestCC(segmentation):\n",
    "    class_list = []\n",
    "    for i in range(1, 4):\n",
    "        temp_prob = segmentation == i * torch.ones_like(segmentation)\n",
    "        temp_prob = temp_prob.detach().cpu().numpy()\n",
    "        labels = label(temp_prob)\n",
    "        # -- with 'try'\n",
    "        assert (labels.max() != 0)  # assume at least 1 CC\n",
    "        largestCC = labels == np.argmax(np.bincount(labels.flat)[1:]) + 1\n",
    "        class_list.append(largestCC * i)\n",
    "    acdc_largestCC = class_list[0] + class_list[1] + class_list[2]\n",
    "    return torch.from_numpy(acdc_largestCC).cuda()\n",
    "\n",
    "\n",
    "def get_ACDC_2DLargestCC(segmentation):\n",
    "    batch_list = []\n",
    "    N = segmentation.shape[0]\n",
    "    for i in range(0, N):\n",
    "        class_list = []\n",
    "        for c in range(1, 4):\n",
    "            temp_seg = segmentation[i]  # == c *  torch.ones_like(segmentation[i])\n",
    "            temp_prob = torch.zeros_like(temp_seg)\n",
    "            temp_prob[temp_seg == c] = 1\n",
    "            temp_prob = temp_prob.detach().cpu().numpy()\n",
    "            labels = label(temp_prob)\n",
    "            if labels.max() != 0:\n",
    "                largestCC = labels == np.argmax(np.bincount(labels.flat)[1:]) + 1\n",
    "                class_list.append(largestCC * c)\n",
    "            else:\n",
    "                class_list.append(temp_prob)\n",
    "\n",
    "        n_batch = class_list[0] + class_list[1] + class_list[2]\n",
    "        batch_list.append(n_batch)\n",
    "\n",
    "    return torch.Tensor(batch_list).cuda()\n",
    "\n",
    "\n",
    "def get_ACDC_masks(output, nms=0):\n",
    "    probs = F.softmax(output, dim=1)\n",
    "    _, probs = torch.max(probs, dim=1)\n",
    "    if nms == 1:\n",
    "        probs = get_ACDC_2DLargestCC(probs)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_loss = DiceLoss(n_classes= 4)\n",
    "def mix_loss(output, img_l, patch_l, mask, l_weight=1.0, u_weight=0.5, unlab=False):\n",
    "    CE = nn.CrossEntropyLoss(reduction='none')\n",
    "    img_l, patch_l = img_l.type(torch.int64), patch_l.type(torch.int64)\n",
    "    output_soft = F.softmax(output, dim=1)\n",
    "    image_weight, patch_weight = l_weight, u_weight\n",
    "    if unlab:\n",
    "        image_weight, patch_weight = u_weight, l_weight\n",
    "    patch_mask = 1 - mask\n",
    "\n",
    "    loss_dice = dice_loss(output_soft, img_l.unsqueeze(1), mask.unsqueeze(1)) * image_weight\n",
    "    loss_dice += dice_loss(output_soft, patch_l.unsqueeze(1), patch_mask.unsqueeze(1)) * patch_weight\n",
    "    loss_ce = image_weight * (CE(output, img_l) * mask).sum() / (mask.sum() + 1e-16)\n",
    "    loss_ce += patch_weight * (CE(output, patch_l) * patch_mask).sum() / (patch_mask.sum() + 1e-16)  # loss = loss_ce\n",
    "    return loss_dice, loss_ce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_train(args, snapshot_path): \n",
    "    # Pretrain\n",
    "    num_clases = args.num_classes\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "\n",
    "    # Load data \n",
    "    db_val = ACDCDataset(base_dir= args.root_dir, split= 'val')\n",
    "\n",
    "    c_batch_size = 12 \n",
    "    trainset_lab_a = ACDCDataset(base_dir= args.root_dir, \n",
    "                                split= 'train_lab', \n",
    "                                transform= transforms.Compose([RandomGenerator(args.patch_size)]))\n",
    "\n",
    "    trainset_lab_b = ACDCDataset(base_dir= args.root_dir, \n",
    "                            split= 'train_lab',\n",
    "                            reverse= True, \n",
    "                            transform= transforms.Compose([RandomGenerator(args.patch_size)]))\n",
    "\n",
    "    train_loader_a = DataLoader(trainset_lab_a, batch_size= c_batch_size, shuffle= False, num_workers= 0, drop_last= True)\n",
    "    train_loader_b = DataLoader(trainset_lab_b, batch_size= c_batch_size, shuffle=False,num_workers= 0, drop_last= True)\n",
    "    val_loader = DataLoader(db_val, batch_size=1, shuffle= False, num_workers=0)\n",
    "\n",
    "\n",
    "    # Network\n",
    "    model1 = BCP_net(model= 'unet', in_chns=1, num_classes= num_clases)\n",
    "    model2 = BCP_net(model= 'ResUnet', in_chns=1, num_classes= num_clases) \n",
    "    optimizer1 = optim.Adam(model1.parameters(), lr= 1e-3)\n",
    "    optimizer2 = optim.Adam(model2.parameters(), lr= 1e-3)\n",
    "    logging.info('optim.Adam pre_train problem')\n",
    "\n",
    "    logging.info('Start pre-traininig')\n",
    "    logging.info(f'{len(train_loader_a)} iterations per epoch ')\n",
    "\n",
    "    model1.train() \n",
    "    model2.train() \n",
    "\n",
    "    iter_num = 0 \n",
    "    best_performance1 = 0.0 \n",
    "    best_performance2 = 0.0 \n",
    "    max_epoch = 10 \n",
    "    iterator = tqdm(range(1, max_epoch), ncols= 70)\n",
    "    for epoch in iterator: \n",
    "        logging.info('\\n')\n",
    "        for step, ((img_a, lab_a), (img_b, lab_b)) in enumerate(zip(train_loader_a, train_loader_b)): \n",
    "            img_a, img_b, lab_a, lab_b = img_a.cuda(), img_b.cuda(), lab_a.cuda(), lab_b.cuda() \n",
    "\n",
    "            img_mask, loss_mask = masks.generate_mask(img_a) \n",
    "\n",
    "            # -- original \n",
    "            net_input = img_a * img_mask + img_b * (1- img_mask) \n",
    "            \n",
    "            out_mixl_1 = model1(net_input) \n",
    "            out_mixl_2 = model2(net_input)\n",
    "\n",
    "            # print(f'Input.shape = {net_input.shape}')\n",
    "            # print(f'Label_a.shape = {lab_a.shape}')\n",
    "            # print(f'Label_b.shape = {lab_b.shape}')\n",
    "            # print(f'Output.shape = {out_mixl_1.shape}')\n",
    "            loss_dice_1, loss_ce_1 = mix_loss(out_mixl_1, lab_a, lab_b, loss_mask, u_weight= 1.0, unlab= True)\n",
    "            loss_dice_2, loss_ce_2 = mix_loss(out_mixl_2, lab_a, lab_b,loss_mask, u_weight= 1.0, unlab= True) \n",
    "\n",
    "            loss1 = (loss_dice_1 + loss_ce_1) / 2 \n",
    "            loss2 = (loss_dice_2 + loss_ce_2) / 2 \n",
    "\n",
    "            optimizer1.zero_grad() \n",
    "            loss1.backward() \n",
    "            optimizer1.step() \n",
    "\n",
    "            optimizer2.zero_grad() \n",
    "            loss2.backward() \n",
    "            optimizer2.step() \n",
    "\n",
    "            iter_num += 1 \n",
    "            logging.info(f'iterations: {iter_num} loss: {loss1} loss_dice: {loss_dice_1} loss_ce: {loss_ce_1}')\n",
    "        \n",
    "        if epoch >= 0 and epoch % 5 == 0: \n",
    "            model1.eval() \n",
    "            model2.eval() \n",
    "            metric_list_1 = 0.0 \n",
    "            metric_list_2 = 0.0 \n",
    "            for _, (img_val, lab_val) in tqdm(enumerate(val_loader), ncols= 70): \n",
    "                metric_i_1 = test_single_volume(img_val, lab_val, model1, classes= num_clases)\n",
    "                metric_i_2 = test_single_volume(img_val, lab_val, model2, classes= num_clases)\n",
    "\n",
    "                metric_list_1 += np.array(metric_i_1)\n",
    "                metric_list_2 += np.array(metric_i_2)\n",
    "            \n",
    "            metric_list_1 = metric_list_1 / len(db_val)\n",
    "            metric_list_2 = metric_list_2 / len(db_val)\n",
    "\n",
    "            performance_1 = np.mean(metric_list_1, axis= 0)[0] \n",
    "            performance_2 = np.mean(metric_list_2, axis= 0)[0] \n",
    "\n",
    "            if performance_1 > best_performance1: \n",
    "                best_performance1 = performance_1 \n",
    "\n",
    "                save_model_path = os.path.join(snapshot_path, f\"iter_{iter_num}_dice_{performance_1:.4f}.pth\")\n",
    "                save_best_path = os.path.join(snapshot_path, 'best_model_1.pth')  \n",
    "\n",
    "                save_net_opt(model1, optimizer1, save_model_path)          \n",
    "                save_net_opt(model1, optimizer1, save_best_path)\n",
    "            \n",
    "            if performance_2 > best_performance2: \n",
    "                best_performance2 = performance_2 \n",
    "\n",
    "                save_model_path = os.path.join(snapshot_path, f\"iter_{iter_num}_dice_{performance_2:.4f}.pth\")\n",
    "                save_best_path = os.path.join(snapshot_path, 'best_model_2.pth')  \n",
    "\n",
    "                save_net_opt(model2, optimizer2, save_model_path)          \n",
    "                save_net_opt(model2, optimizer2, save_best_path)\n",
    "\n",
    "            logging.info('iteration %d : mean_dice : %f, val_maxdice : %f' % (iter_num, performance_1, best_performance1))\n",
    "            logging.info('resnet iteration %d : mean_dice : %f, val_maxdice : %f' % (iter_num, performance_2, best_performance2))\n",
    "            model1.train()\n",
    "            model2.train() \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support self-train ----- NEED TO UNDERSTAND AGAIN !!!!!  \n",
    "def softmax_mse_loss(input_logits, target_logits):\n",
    "    \"\"\"Takes softmax on both sides and returns MSE loss\n",
    "    Note:\n",
    "    - Returns the sum over all examples. Divide by the batch size afterwards\n",
    "      if you want the mean.\n",
    "    - Sends gradients to inputs but not the targets.\n",
    "    \"\"\"\n",
    "    assert input_logits.size() == target_logits.size()\n",
    "    input_softmax = F.softmax(input_logits, dim=1)\n",
    "    # target_softmax = F.softmax(target_logits, dim=1)\n",
    "    mse_loss = (input_softmax - target_logits) ** 2\n",
    "    return mse_loss\n",
    "\n",
    "def to_one_hot(tensor, nClasses):\n",
    "    \"\"\" Input tensor : Nx1xHxW\n",
    "    :param tensor:\n",
    "    :param nClasses:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert tensor.max().item() < nClasses, 'one hot tensor.max() = {} < {}'.format(torch.max(tensor), nClasses)\n",
    "    assert tensor.min().item() >= 0, 'one hot tensor.min() = {} < {}'.format(tensor.min(), 0)\n",
    "\n",
    "    size = list(tensor.size())\n",
    "    assert size[1] == 1\n",
    "    size[1] = nClasses\n",
    "    one_hot = torch.zeros(*size)\n",
    "    if tensor.is_cuda:\n",
    "        one_hot = one_hot.cuda(tensor.device)\n",
    "    one_hot = one_hot.scatter_(1, tensor, 1)\n",
    "    return one_hot\n",
    "\n",
    "def get_XOR_region(mixout1, mixout2): \n",
    "    s1 = torch.softmax(mixout1, dim=1)\n",
    "    l1 = torch.argmax(s1, dim=1) \n",
    "    s2 = torch.softmax(mixout2, dim=1) \n",
    "    l2 = torch.argmax(s2, dim= 1) \n",
    "\n",
    "    diff_mask = (l1 != l2) \n",
    "    return diff_mask\n",
    "\n",
    "def mix_mse_loss(net3_output, img_l, patch_l, mask= None, l_weight=1.0, u_weight=0.5, unlab= False, diff_mask=None): \n",
    "    img_l, patch_l = img_l.type(torch.int64),patch_l.type(torch.int64) \n",
    "    image_weight, patch_weight = l_weight, u_weight\n",
    "    if unlab: \n",
    "        image_weight, patch_weight = u_weight, l_weight\n",
    "\n",
    "    patch_mask = 1 - mask \n",
    "    img_l_onehot = to_one_hot(img_l.unsqueeze(1), 4)\n",
    "    patch_l_onehot = to_one_hot(patch_l.unsqueeze(1), 4)\n",
    "\n",
    "    mse_loss = torch.mean(softmax_mse_loss(net3_output,img_l_onehot), dim=1)*mask * image_weight\n",
    "    mse_loss += torch.mean(softmax_mse_loss(net3_output, patch_l_onehot), dim= 1) * patch_mask * patch_weight\n",
    "\n",
    "    loss = torch.sum(diff_mask * mse_loss) / (torch.sum(diff_mask) + 1e-16)\n",
    "    return loss \n",
    "     \n",
    "voxel_kl_loss = nn.KLDivLoss(reduction='none')\n",
    "def mix_max_kl_loss(net3_output, img_l, patch_l, mask, l_weight=1.0, u_weight=0.5, unlab=False, diff_mask=None):\n",
    "    img_l, patch_l = img_l.type(torch.int64), patch_l.type(torch.int64)\n",
    "\n",
    "    image_weight, patch_weight = l_weight, u_weight\n",
    "    if unlab:\n",
    "        image_weight, patch_weight = u_weight, l_weight\n",
    "\n",
    "    patch_mask = 1 - mask\n",
    "\n",
    "    with torch.no_grad():\n",
    "        s1 = torch.softmax(net3_output, dim=1)\n",
    "        l1 = torch.argmax(s1, dim=1)\n",
    "        img_diff_mask = (l1 != img_l)\n",
    "        patch_diff_mask = (l1 != patch_l)\n",
    "\n",
    "        uniform_distri = torch.ones(net3_output.shape)\n",
    "        uniform_distri = uniform_distri.cuda()\n",
    "\n",
    "    kl_loss = torch.mean(voxel_kl_loss(F.log_softmax(net3_output, dim=1), uniform_distri),\n",
    "                         dim=1) * mask * img_diff_mask * image_weight\n",
    "    kl_loss += torch.mean(voxel_kl_loss(F.log_softmax(net3_output, dim=1), uniform_distri),\n",
    "                          dim=1) * patch_mask * patch_diff_mask * patch_weight\n",
    "\n",
    "    sum_diff = torch.sum(mask * img_diff_mask * diff_mask) + torch.sum(patch_mask * patch_diff_mask * diff_mask)\n",
    "    loss = torch.sum(diff_mask * kl_loss) / (sum_diff + 1e-16)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: val: 20 samples in total\n",
      "Mode: train_lab: 136 samples in total\n",
      "Mode: train_unlab: 1176 samples in total\n",
      "Mode: train_lab: 136 samples in total\n",
      "Mode: train_unlab: 1176 samples in total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:18,  1.10it/s]                | 1/9 [01:40<13:25, 100.65s/it]\n",
      " 11%|███▊                              | 1/9 [03:13<25:48, 193.52s/it]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_performance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 160\u001b[0m\n\u001b[1;32m    157\u001b[0m performance2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(metric_list_2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    158\u001b[0m performance_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(metric_list_mean, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m performance \u001b[38;5;241m>\u001b[39m \u001b[43mbest_performance\u001b[49m:\n\u001b[1;32m    161\u001b[0m     best_performance \u001b[38;5;241m=\u001b[39m performance\n\u001b[1;32m    162\u001b[0m     save_mode_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(snapshot_path,\n\u001b[1;32m    163\u001b[0m                                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miter_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_dice_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(iter_num, \u001b[38;5;28mround\u001b[39m(best_performance, \u001b[38;5;241m4\u001b[39m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_performance' is not defined"
     ]
    }
   ],
   "source": [
    "# self-train \n",
    "pre_snapshot_path = 'modelSDCL' \n",
    "snapshot_path = 'Idontknow'\n",
    "\n",
    "num_classes = args.num_classes\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "\n",
    "# Load data \n",
    "db_val = ACDCDataset(base_dir= args.root_dir, split= 'val')\n",
    "c_batch_size = 12 \n",
    "trainset_lab_a = ACDCDataset(base_dir= args.root_dir, \n",
    "                             split= 'train_lab', \n",
    "                             transform= transforms.Compose([RandomGenerator(args.patch_size)]))\n",
    "trainset_unlab_a = ACDCDataset(base_dir= args.root_dir, \n",
    "                            split= 'train_unlab', \n",
    "                            transform= transforms.Compose([RandomGenerator(args.patch_size)]))\n",
    "\n",
    "trainset_lab_b = ACDCDataset(base_dir= args.root_dir, \n",
    "                             split= 'train_lab', \n",
    "                             reverse= True, \n",
    "                             transform= transforms.Compose([RandomGenerator(args.patch_size)]))\n",
    "trainset_unlabel_b = ACDCDataset(base_dir= args.root_dir, \n",
    "                                 split= 'train_unlab', \n",
    "                                 reverse= True, \n",
    "                                 transform= transforms.Compose([RandomGenerator(args.patch_size)]))\n",
    "\n",
    "lab_loader_a = DataLoader(trainset_lab_a, batch_size= c_batch_size, shuffle= False, num_workers= 0, drop_last= True)\n",
    "lab_loader_b = DataLoader(trainset_lab_b, batch_size= c_batch_size, shuffle= False, num_workers= 0, drop_last= True) \n",
    "unlab_loader_a = DataLoader(trainset_unlab_a, batch_size= c_batch_size, shuffle= False, num_workers=0, drop_last= True) \n",
    "unlab_loader_b = DataLoader(trainset_unlabel_b, batch_size= c_batch_size, shuffle= False, num_workers=0, drop_last= True) \n",
    "valloader = DataLoader(db_val, batch_size=1, shuffle= False, num_workers=1)\n",
    "\n",
    "# Prepare model\n",
    "pre_train_model1 = os.path.join(pre_snapshot_path, 'best_model_1.pth')\n",
    "pre_train_model2 = os.path.join(pre_snapshot_path, 'best_model_2.pth')\n",
    "\n",
    "model1 = BCP_net(model= 'unet', in_chns=1, num_classes= num_classes)\n",
    "model2 = BCP_net(model= 'ResUnet', in_chns= 1, num_classes= num_classes)\n",
    "ema_model = BCP_net(model= 'unet', in_chns=1, num_classes= num_classes, ema= True)\n",
    "\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr= 1e-3)\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr= 1e-3)\n",
    "\n",
    "load_net_opt(ema_model, optimizer1, pre_train_model1)\n",
    "load_net_opt(model1, optimizer1, pre_train_model1)\n",
    "load_net_opt(model2, optimizer2, pre_train_model2)\n",
    "logging.info(f'Load from {pre_snapshot_path}')\n",
    "\n",
    "logging.info('Start self-training')\n",
    "model1.train() \n",
    "model2.train() \n",
    "ema_model.train() \n",
    "\n",
    "iter_num = 0 \n",
    "best_performance_1 = 0.0 \n",
    "best_performance_2 = 0.0 \n",
    "best_performance_mean = 0.0 \n",
    "\n",
    "max_epoch = 10 \n",
    "iterator = tqdm(range(1, max_epoch), ncols= 70) \n",
    "for epoch in iterator: \n",
    "    for step, ((img_a, lab_a), (img_b, lab_b), (unimg_a, unlab_a), (unimg_b, unlab_b)) in enumerate(zip(lab_loader_a, lab_loader_b, unlab_loader_a, unlab_loader_b)):\n",
    "        img_a, lab_a, img_b, lab_b, unimg_a, unlab_a, unimg_b, unlab_b = img_a.cuda(), lab_a.cuda(), img_b.cuda(), lab_b.cuda(), unimg_a.cuda(), unlab_a.cuda(), unimg_b.cuda(), unlab_b.cuda()\n",
    "\n",
    "        # Pseudo label        \n",
    "        with torch.no_grad(): \n",
    "            pre_a = ema_model(unimg_a)\n",
    "            pre_b = ema_model(unimg_b)\n",
    "            plab_a = get_ACDC_masks(pre_a, nms=1)\n",
    "            plab_b = get_ACDC_masks(pre_b, nms=1)\n",
    "\n",
    "            img_mask, loss_mask = masks.generate_mask(img_a)\n",
    "        \n",
    "        # BCP problem \n",
    "        net_input_l = unimg_a * img_mask + img_b*(1- img_mask)\n",
    "        net_input_unl = img_a * img_mask + unimg_b * ( 1 - img_mask)\n",
    "\n",
    "        out_l_1 =  model1(net_input_l)\n",
    "        out_unl_1 = model1(net_input_unl)\n",
    "        out_l_2 = model2(net_input_l)\n",
    "        out_unl_2 = model2((net_input_unl))\n",
    "\n",
    "        l_dice_1, l_ce_1 = mix_loss(out_l_1, plab_a, lab_b, loss_mask, u_weight= args.u_weight, unlab= True) \n",
    "        un_dice_1, un_ce_1 = mix_loss(out_unl_1, lab_a, plab_b, loss_mask, u_weight= args.u_weight)\n",
    "\n",
    "        l_dice_2, l_ce_2 = mix_loss(out_l_2, plab_a, lab_b, loss_mask, u_weight= args.u_weight, unlab= True) \n",
    "        un_dice_2, un_ce_2 = mix_loss(out_unl_2, lab_a, plab_b, loss_mask, u_weight= args.u_weight, unlab= True) \n",
    "        \n",
    "        # Average loss \n",
    "        loss_dice_1 = l_dice_1 + un_dice_1\n",
    "        loss_ce_1 = l_ce_1 + un_ce_1\n",
    "        loss_dice_2 = l_dice_2 + un_dice_2 \n",
    "        loss_ce_2 = l_ce_2 + un_ce_2  \n",
    "\n",
    "        with torch.no_grad(): \n",
    "            diff_mask1 = get_XOR_region(out_l_1, out_l_2)\n",
    "            diff_mask_2 = get_XOR_region(out_unl_1, out_unl_2)\n",
    "        \n",
    "        net1_mse_loss_lab = mix_mse_loss(out_l_1, plab_a.long(), lab_b, loss_mask, unlab= True, diff_mask= diff_mask1)\n",
    "        net1_kl_loss_lab = mix_max_kl_loss(out_l_1, plab_a.long(), lab_b, loss_mask, unlab= True, diff_mask= diff_mask1)\n",
    "\n",
    "        net1_mse_loss_unlab = mix_mse_loss(out_unl_1, lab_a, plab_b.long(), loss_mask, diff_mask= diff_mask_2)\n",
    "        net1_kl_loss_unlab = mix_max_kl_loss(out_unl_1, lab_a, plab_b.long(), loss_mask, diff_mask= diff_mask_2)\n",
    "\n",
    "        net2_mse_loss_lab = mix_mse_loss(out_l_2, plab_a.long(), lab_b, loss_mask, unlab= True, diff_mask= diff_mask1)\n",
    "        net2_kl_loss_lab = mix_max_kl_loss(out_l_2, lab_a, plab_b.long(), loss_mask, unlab= True, diff_mask= diff_mask1)\n",
    "\n",
    "        net2_mse_loss_unlab = mix_mse_loss(out_unl_2, lab_a, plab_b.long(), loss_mask, diff_mask= diff_mask_2)\n",
    "        net2_kl_loss_unlab = mix_max_kl_loss(out_unl_2, lab_a, plab_b.long(), loss_mask, diff_mask= diff_mask_2)\n",
    "\n",
    "        loss_1 = (loss_dice_1 + loss_ce_1)/2 + 0.5 * (net1_mse_loss_lab + net1_kl_loss_lab) + 0.05 * (net1_kl_loss_lab + net1_kl_loss_unlab)\n",
    "        loss_2 = (loss_dice_2 + loss_ce_2)/2 + 0.5 * (net2_mse_loss_lab + net2_mse_loss_unlab) + 0.05 * (net2_kl_loss_lab + net2_kl_loss_unlab)\n",
    "\n",
    "        optimizer1.zero_grad() \n",
    "        loss_1.backward()\n",
    "        optimizer1.step() \n",
    "\n",
    "        optimizer2.zero_grad() \n",
    "        loss_2.backward() \n",
    "        optimizer2.step() \n",
    "\n",
    "        iter_num += 1 \n",
    "        update_model_ema(model1, ema_model, 0.99)\n",
    "        \n",
    "\n",
    "        logging.info({\n",
    "            'iter': iter_num,\n",
    "            'mix_dice': loss_dice_1.item(),\n",
    "            'mix_ce': loss_ce_1.item(),\n",
    "            'mse_lab': net1_mse_loss_lab.item(),\n",
    "            'mse_unlab': net1_mse_loss_unlab.item(),\n",
    "            'kl_lab': net1_kl_loss_lab.item(),\n",
    "            'kl_unlab': net1_kl_loss_unlab.item()\n",
    "        })\n",
    "\n",
    "        if iter_num % 200 == 0:\n",
    "            model1.eval()\n",
    "            model2.eval()\n",
    "            metric_list = 0.0\n",
    "            metric_list_2 = 0.0\n",
    "            metric_list_mean = 0.0\n",
    "\n",
    "            for _, (img_val, lab_val) in tqdm(enumerate(valloader), ncols=70):\n",
    "                metric_i = test_single_volume(img_val, lab_val, model1, classes=num_classes)\n",
    "                metric_i_2 = test_single_volume(img_val, lab_val, model2, classes=num_classes)\n",
    "                metric_i_mean = test_single_volume_mean(img_val, lab_val, model1, model2, classes=num_classes)\n",
    "\n",
    "                metric_list += np.array(metric_i)\n",
    "                metric_list_2 += np.array(metric_i_2)\n",
    "                metric_list_mean += np.array(metric_i_mean)\n",
    "\n",
    "            metric_list = metric_list / len(db_val)\n",
    "            metric_list_2 = metric_list_2 / len(db_val)\n",
    "            metric_list_mean = metric_list_mean / len(db_val)\n",
    "\n",
    "            performance_1 = np.mean(metric_list, axis=0)[0]\n",
    "            performance_2 = np.mean(metric_list_2, axis=0)[0]\n",
    "            performance_mean = np.mean(metric_list_mean, axis=0)[0]\n",
    "\n",
    "            if performance_1 > best_performance_1:\n",
    "                best_performance_1 = performance_1\n",
    "                save_mode_path = os.path.join(snapshot_path,\n",
    "                                                'iter_{}_dice_{}.pth'.format(iter_num, round(best_performance_1, 4)))\n",
    "                save_best_path = os.path.join(snapshot_path, 'best_model.pth')\n",
    "                save_net_opt(model1, optimizer1, save_mode_path)\n",
    "                save_net_opt(model1, optimizer1, save_best_path)\n",
    "\n",
    "            if performance_2 > best_performance_2:\n",
    "                best_performance_2 = performance_2\n",
    "                save_mode_path = os.path.join(snapshot_path,\n",
    "                                                'iter_{}_dice_{}_res.pth'.format(iter_num, round(best_performance_2, 4)))\n",
    "                save_best_path = os.path.join(snapshot_path, 'best_model_res.pth')\n",
    "                save_net_opt(model2, optimizer2, save_mode_path)\n",
    "                save_net_opt(model2, optimizer2, save_best_path)\n",
    "\n",
    "            if performance_mean > best_performance_mean:\n",
    "                best_performance_mean = performance_mean\n",
    "\n",
    "                save_mode_path1 = os.path.join(snapshot_path, 'iter_{}_dice_{}_v.pth'.format(iter_num, round(\n",
    "                    best_performance_mean, 4)))\n",
    "                save_best_path1 = os.path.join(snapshot_path, 'best_model_v.pth')\n",
    "\n",
    "                save_mode_path2 = os.path.join(snapshot_path, 'iter_{}_dice_{}_r.pth'.format(iter_num, round(\n",
    "                    best_performance_mean, 4)))\n",
    "                save_best_path2 = os.path.join(snapshot_path, 'best_model_r.pth')\n",
    "\n",
    "                save_net_opt(model1, optimizer1, save_mode_path1)\n",
    "                save_net_opt(model1, optimizer1, save_best_path1)\n",
    "\n",
    "                save_net_opt(model2, optimizer2, save_mode_path2)\n",
    "                save_net_opt(model2, optimizer2, save_best_path2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
