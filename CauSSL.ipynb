{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import random \n",
    "import time \n",
    "import logging \n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import torch \n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "from utils.params import params \n",
    "from utils.losses import DiceLoss, softmax_mse_loss, softmax_kl_loss, l_correlation_cos_mean\n",
    "from networks.utils import BCP_net, get_current_consistency_weight, update_ema_variable\n",
    "from dataset.basedataset import BaseDataset\n",
    "from dataset.utils import TwoStreamBatchSampler, RandomGenerator, patients_to_slices\n",
    "\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. ACDC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labeled data in used: 10.0%\n",
      "X.shape = torch.Size([24, 1, 256, 256])\n",
      "Y.shape = torch.Size([24, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# load dataset \n",
    "train_db = BaseDataset(\n",
    "    root_path= args.root_dir, \n",
    "    split= 'train', \n",
    "    transform= transforms.Compose([RandomGenerator(args.patch_size)])\n",
    ")\n",
    "\n",
    "val_db = BaseDataset(\n",
    "    root_path= args.root_dir, \n",
    "    split= 'val'\n",
    ")\n",
    "\n",
    "\n",
    "# split to labeled and unlabeled dataset \n",
    "labeled_slices = patients_to_slices(args.root_dir, args.label_num) \n",
    "label_ratio = round(labeled_slices / len(train_db), 1)* 100\n",
    "print(f'Number of labeled data in used: {label_ratio}%')\n",
    "labeled_idxs = list(range(0, labeled_slices) )\n",
    "unlabeled_idxs = list(range(labeled_slices ,len(train_db)))\n",
    "batch_sampler = TwoStreamBatchSampler(labeled_idxs, unlabeled_idxs, args.batch_size, args.batch_size - args.labeled_bs)\n",
    "\n",
    "# Create dataloader\n",
    "def worker_init_fn(worker_id):\n",
    "    random.seed(args.seed + worker_id)\n",
    " \n",
    "trainloader = DataLoader(train_db, batch_sampler= batch_sampler, num_workers= 4, pin_memory= True, worker_init_fn= worker_init_fn)\n",
    "valloader = DataLoader(val_db, batch_size= 1, shuffle= False, num_workers=1)\n",
    "\n",
    "# Check \n",
    "dataiter = iter(trainloader) \n",
    "sampled_batch = next(dataiter) \n",
    "volume_image, volume_label = sampled_batch['image'], sampled_batch['label']\n",
    "volume_image, volume_label = volume_image.cuda(), volume_label.cuda()\n",
    "labeled_volume_batch = volume_image[ : args.labeled_bs]\n",
    "unlabeled_volume_batch = volume_image[args.labeled_bs :]\n",
    "print(f'X.shape = {volume_image.shape}')\n",
    "print(f'Y.shape = {volume_label.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Linear Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_vector(nn.Module): \n",
    "    \"\"\"\n",
    "    Implement: \n",
    "        - Initialize the linear transform matrix. G.shape = (ndim, ndim) \n",
    "        - Apply Gb to performce linear transform \n",
    "    Formula: \n",
    "        qb.shape = G * w --> (ndim, k)\n",
    "        w.shape = (ndim, k)\n",
    "        G.shape = (ndim, ndim) \n",
    "    \"\"\"\n",
    "    def __init__(self, ndim): \n",
    "        super(Linear_vector, self).__init__()\n",
    "        self.ndim = ndim \n",
    "        self.params = Parameter(torch.Tensor(self.ndim, self.ndim)) # Linear transform matrix\n",
    "        self.ratio_init = 0.3 \n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        \"\"\" \n",
    "        Initialize for Standard Scaler \n",
    "        mean = 0 \n",
    "        std = ratio_init \n",
    "        \"\"\" \n",
    "        for param in self.params: \n",
    "            param.data.normal_(0, self.ratio_init)  \n",
    "\n",
    "    def forward(self,x):\n",
    "        result = torch.mm(self.params, x) # dot product  \n",
    "        return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "ndim = 64 \n",
    "k = 10 \n",
    "w1 = torch.randn(ndim, k) \n",
    "w2 = torch.randn(ndim, k)\n",
    "linear_trans1 = Linear_vector(ndim= 64)\n",
    "\n",
    "q21 = linear_trans1(w2) \n",
    "print(q21.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Understand Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output.shape = torch.Size([24, 4, 256, 256])\n",
      "Type of output: torch.float32\n"
     ]
    }
   ],
   "source": [
    "base_model = BCP_net(in_chns= 1, class_num= args.num_classes) \n",
    "outputs = base_model(volume_image)\n",
    "print(f'Output.shape = {outputs.shape}')\n",
    "print(f'Type of output: {outputs.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_loss_fn = DiceLoss(n_classes= 4) \n",
    "def supervised_loss(outputs, target, alpha= 0.5): \n",
    "    \"\"\"\n",
    "    Comptute supervised loss for CauSSL (on labeled data only)\n",
    "    supervised = 0.5 ( CE + DICE )\n",
    "    \"\"\"\n",
    "    # Compute CELoss \n",
    "    target = target.long() \n",
    "    loss_ce = F.cross_entropy(outputs, target) \n",
    "\n",
    "    # Compute DiceLoss \n",
    "    loss_dice = dice_loss_fn(outputs, target.unsqueeze(1)) \n",
    "\n",
    "    loss = alpha * ( loss_ce + loss_dice)\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Training process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 7.79 GiB of which 66.88 MiB is free. Including non-PyTorch memory, this process has 7.66 GiB memory in use. Of the allocated memory 7.45 GiB is allocated by PyTorch, and 46.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 81\u001b[0m\n\u001b[1;32m     78\u001b[0m unlabeled_batch \u001b[38;5;241m=\u001b[39m volume_batch[labeled_bs :]\n\u001b[1;32m     80\u001b[0m outputs1 \u001b[38;5;241m=\u001b[39m model1(volume_batch)\n\u001b[0;32m---> 81\u001b[0m outputs2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvolume_batch\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     83\u001b[0m supervised_loss1 \u001b[38;5;241m=\u001b[39m supervised_loss(outputs1[: labeled_bs], volume_batch[labeled_bs])\n\u001b[1;32m     84\u001b[0m supervised_loss2 \u001b[38;5;241m=\u001b[39m supervised_loss(outputs2[: labeled_bs], label_batch[: labeled_bs])\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/pythonCode/SSL4MIS/BCP/Medical_Seg_Semi/networks/UNet2D.py:130\u001b[0m, in \u001b[0;36mUNet_2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x): \n\u001b[1;32m    129\u001b[0m     feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x) \n\u001b[0;32m--> 130\u001b[0m     output, features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/pythonCode/SSL4MIS/BCP/Medical_Seg_Semi/networks/UNet2D.py:109\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, feature)\u001b[0m\n\u001b[1;32m    107\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup2(x, x2)\n\u001b[1;32m    108\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup3(x, x1)\n\u001b[0;32m--> 109\u001b[0m x_last \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x_last) \n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, x_last\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearning/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/pythonCode/SSL4MIS/BCP/Medical_Seg_Semi/networks/UNet2D.py:54\u001b[0m, in \u001b[0;36mUpBlock.forward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     52\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvx1(x1) \n\u001b[1;32m     53\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup(x1) \n\u001b[0;32m---> 54\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 7.79 GiB of which 66.88 MiB is free. Including non-PyTorch memory, this process has 7.66 GiB memory in use. Of the allocated memory 7.45 GiB is allocated by PyTorch, and 46.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "num_classes = args.num_classes\n",
    "base_lr = args.base_lr \n",
    "labeled_bs = args.labeled_bs\n",
    "max_iterations = args.max_iteration\n",
    "\n",
    "# create 2 model with the same architecure\n",
    "model1 = BCP_net(in_chns=1, class_num= 4) \n",
    "model2 = BCP_net(in_chns=1, class_num= 4) \n",
    "optimizer1 = optim.SGD(model1.parameters(), base_lr,  momentum= 0.9, weight_decay= 1e-4)\n",
    "optimizer2 = optim.SGD(model2.parameters(), base_lr, momentum= 0.9, weight_decay= 1e-4)\n",
    "\n",
    "model1.train() \n",
    "model2.train() \n",
    "\n",
    "# Initialize linear transform matrix (vector)\n",
    "linear_params1 = [] \n",
    "linear_params2 = [] \n",
    "count = 0\n",
    "for name, parameters in model1.named_parameters(): \n",
    "    if 'conv' in name and 'weight' in name: \n",
    "        if len(parameters.shape) == 4: \n",
    "            count += 1 \n",
    "            outdim = parameters.shape[0] \n",
    "            linear_params1.append(Linear_vector(outdim))\n",
    "            linear_params2.append(Linear_vector(outdim))\n",
    "\n",
    "# Convert from list to torch\n",
    "linear_params1 = nn.ModuleList(linear_params1)\n",
    "linear_params2 = nn.ModuleList(linear_params2)    \n",
    "linear_params1 = linear_params1.cuda() \n",
    "linear_params2 = linear_params2.cuda()\n",
    "\n",
    "linear_optimizer1 = optim.Adam(linear_params1.parameters(), 2e-2) # Need consider about this hyper-parameters\n",
    "linear_optimizer2 = optim.Adam(linear_params2.parameters(), 2e-2)\n",
    "\n",
    "if args.consistency_type == 'mse': \n",
    "    consistency_criterion = softmax_mse_loss\n",
    "elif args.consistency_type == 'kl': \n",
    "    consistency_criterion = softmax_kl_loss\n",
    "else: \n",
    "    assert False, args.consistency_type\n",
    "\n",
    "# Training process - Cross Pseudo Supervision FrameWork \n",
    "writer = SummaryWriter() \n",
    "logging.info(f'{len(trainloader)} per epoch')\n",
    "\n",
    "iter_num = 0 \n",
    "iter_num_max = 0 \n",
    "max_epoch = max_iterations // len(trainloader) + 1 \n",
    "lr_ = base_lr \n",
    "model1.train() \n",
    "model2.train() \n",
    "for epoch_num in tqdm(range(max_epoch), ncols=70): \n",
    "    time1 = time.time() \n",
    "    for i_batch, sampled_batch in enumerate(trainloader): \n",
    "        time2 = time.time() \n",
    "\n",
    "        # Update linear transform matrix periodly \n",
    "        if iter_num > args.start_step1 and iter_num % args.min_step == 0: \n",
    "            icm_loss1 = -l_correlation_cos_mean(model1, model2, linear_params1)\n",
    "            icm_loss2 = -l_correlation_cos_mean(model1, model2, linear_params2)\n",
    "\n",
    "            linear_optimizer1.zero_grad() \n",
    "            linear_optimizer2.zero_grad() \n",
    "\n",
    "            icm_loss1.backward() \n",
    "            icm_loss2.backward() \n",
    "            linear_optimizer1.step() \n",
    "            linear_optimizer2.step() \n",
    "\n",
    "            iter_num_max += 1 \n",
    "\n",
    "            writer.add_scalar('loss/icm_loss1_max', -icm_loss1, iter_num_max)\n",
    "            writer.add_scalar('loss/icm_loss2_max', -icm_loss2, iter_num_max)\n",
    "        \n",
    "        volume_batch, label_batch = sampled_batch['image'], sampled_batch['label']\n",
    "        volume_batch, label_batch = volume_batch.cuda(), label_batch.cuda() \n",
    "        unlabeled_batch = volume_batch[labeled_bs :]\n",
    "\n",
    "        outputs1 = model1(volume_batch)\n",
    "        outputs2 = model2(volume_batch) \n",
    "\n",
    "        supervised_loss1 = supervised_loss(outputs1[: labeled_bs], volume_batch[labeled_bs])\n",
    "        supervised_loss2 = supervised_loss(outputs2[: labeled_bs], label_batch[: labeled_bs])\n",
    "        print(supervised_loss1)\n",
    "        break \n",
    "    break \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
