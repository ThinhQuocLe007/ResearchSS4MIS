{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d235d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9675135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import logging\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from skimage.measure import label \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "\n",
    "# module \n",
    "from networks.net_factory import BCP_net\n",
    "from dataset.basedataset import ACDCDataset\n",
    "from dataset.utils import RandomGenerator, ACDC_patients_to_slices, TwoStreamBatchSampler\n",
    "from utils.params import params \n",
    "from utils.masks import generate_mask, random_mask, contact_mask\n",
    "from utils.losses import mix_loss\n",
    "from utils.valid2d import test_single_volume\n",
    "from networks.utils import save_net_opt, load_net_opt, load_net, get_current_consistency_weight, update_model_ema\n",
    "from MAE.maeLoss import reconstruction_loss\n",
    "from MAE.maskImage import mask_image\n",
    "\n",
    "# writer \n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaf1ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = params() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bea6e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ACDC_2DLargestCC(segmentation):\n",
    "    batch_list = []\n",
    "    N = segmentation.shape[0]\n",
    "    for i in range(0, N):\n",
    "        class_list = []\n",
    "        for c in range(1, 4):\n",
    "            temp_seg = segmentation[i] #== c *  torch.ones_like(segmentation[i])\n",
    "            temp_prob = torch.zeros_like(temp_seg)\n",
    "            temp_prob[temp_seg == c] = 1\n",
    "            temp_prob = temp_prob.detach().cpu().numpy()\n",
    "            labels = label(temp_prob)          \n",
    "            if labels.max() != 0:\n",
    "                largestCC = labels == np.argmax(np.bincount(labels.flat)[1:])+1\n",
    "                class_list.append(largestCC * c)\n",
    "            else:\n",
    "                class_list.append(temp_prob)\n",
    "        \n",
    "        n_batch = class_list[0] + class_list[1] + class_list[2]\n",
    "        batch_list.append(n_batch)\n",
    "\n",
    "    return torch.Tensor(batch_list).cuda()\n",
    "    \n",
    "def get_ACDC_masks(output, nms=0):\n",
    "    probs = F.softmax(output, dim=1)\n",
    "    _, probs = torch.max(probs, dim=1)\n",
    "    if nms == 1:\n",
    "        probs = get_ACDC_2DLargestCC(probs)      \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41399da2",
   "metadata": {},
   "source": [
    "#### 1. BCP network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5859cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain(args, snapshot_path): \n",
    "    base_lr = args.base_lr\n",
    "    num_classes = args.num_classes\n",
    "    max_iterations = args.pretrain_iterations\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu \n",
    "    labeled_bs = args.labeled_bs \n",
    "\n",
    "    # Load data \n",
    "    def worker_init_fn(worker_id):\n",
    "        random.seed(args.seed + worker_id) \n",
    "\n",
    "    label_sub_bs, unlabeled_sub_bs = int(args.labeled_bs / 2), int((args.batch_size - args.labeled_bs)/2) \n",
    "    db_train = ACDCDataset(base_dir= args.root_dir, split= 'train', \n",
    "                        transform= transforms.Compose([RandomGenerator(args.patch_size)]))\n",
    "    db_val = ACDCDataset(base_dir= args.root_dir, split= 'val')\n",
    "    total_slices = len(db_train)\n",
    "    labeled_slices = ACDC_patients_to_slices(args.root_dir, args.label_num)\n",
    "    print(f'Total slices is: {total_slices}, labeled slices is: {labeled_slices}')\n",
    "    labeled_idxes = list(range(0, labeled_slices))\n",
    "    unlabeled_idxes = list(range(labeled_slices, total_slices))\n",
    "    batch_sampler = TwoStreamBatchSampler(labeled_idxes, unlabeled_idxes, args.batch_size, args.batch_size - args.labeled_bs)\n",
    "\n",
    "    trainloader = DataLoader(db_train, batch_sampler= batch_sampler, num_workers= 4, pin_memory= True, worker_init_fn= worker_init_fn)\n",
    "    valloader = DataLoader(db_val, batch_size=1, shuffle= False, num_workers= 1)\n",
    "\n",
    "    # Model \n",
    "    model = BCP_net(in_chns=1, num_classes= num_classes)\n",
    "    optimizer = optim.SGD(model.parameters(), lr= base_lr, momentum= 0.9, weight_decay= 0.0001)\n",
    "\n",
    "    writer = SummaryWriter(snapshot_path + '/log')\n",
    "    logging.info('Start pre_training')\n",
    "    logging.info(f'{len(trainloader)} iterations per epoch')\n",
    "\n",
    "    model.train() \n",
    "    iter_num = 0 \n",
    "    max_epoch = max_iterations // len(trainloader) + 1 \n",
    "    best_performance = 0.0 \n",
    "    best_hd = 100 \n",
    "    iterator = tqdm(range(max_epoch), ncols= 70) \n",
    "    for _ in iterator: \n",
    "        for _, sampled_batch in enumerate(trainloader): \n",
    "            volume_batch, label_batch = sampled_batch['image'], sampled_batch['label']\n",
    "            volume_batch, label_batch = volume_batch.cuda(), label_batch.cuda() \n",
    "\n",
    "            # Create BCP image \n",
    "            img_a, img_b = volume_batch[: label_sub_bs], volume_batch[label_sub_bs : labeled_bs]\n",
    "            lab_a, lab_b = label_batch[: label_sub_bs], label_batch[label_sub_bs: labeled_bs]\n",
    "            img_mask, loss_mask =  generate_mask(img_a)\n",
    "            gt_mixl = lab_a * img_mask + lab_b * (1 - img_mask)\n",
    "\n",
    "            # Feed to model \n",
    "            net_input = img_a * img_mask + img_b * (1 - img_mask)\n",
    "            out_mixl = model(net_input, mode = 'seg')\n",
    "            loss_dice, loss_ce = mix_loss(out_mixl, lab_a, lab_b, loss_mask, u_weight= 1.0, unlab= True)\n",
    "\n",
    "            loss = (loss_dice + loss_ce ) / 2 \n",
    "            optimizer.zero_grad() \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            iter_num += 1 \n",
    "\n",
    "            writer.add_scalar('info/total loss', loss, iter_num)\n",
    "            writer.add_scalar('info/mix_dice', loss_dice, iter_num)\n",
    "            writer.add_scalar('info/mix_ce', loss_ce, iter_num)\n",
    "\n",
    "            logging.info(f'iteration: {iter_num}, loss: {loss}, mix_dice: {loss_dice}, mix_ce: {loss_ce}')\n",
    "            if iter_num % 20 == 0:\n",
    "                image = net_input[1, 0:1, :, :]  # shape = [1, H, W]\n",
    "                image = (image - image.min()) / (image.max() - image.min() + 1e-5)  # normalize to [0,1]\n",
    "                writer.add_image('pre_train/Mixed_Image', image, iter_num)\n",
    "                outputs = torch.argmax(torch.softmax(out_mixl, dim=1), dim=1, keepdim=True)\n",
    "                writer.add_image('pre_train/Mixed_Prediction', outputs[1, ...] * 50, iter_num)\n",
    "                labs = gt_mixl[1, ...].unsqueeze(0) * 50\n",
    "                writer.add_image('pre_train/Mixed_GroundTruth', labs, iter_num)\n",
    "\n",
    "            if iter_num > 0 and iter_num % 200 == 0:\n",
    "                model.eval()\n",
    "                metric_list = 0.0\n",
    "                for _, sampled_batch in enumerate(valloader):\n",
    "                    metric_i = test_single_volume(sampled_batch[\"image\"], sampled_batch[\"label\"], model, classes=num_classes)\n",
    "                    metric_list += np.array(metric_i)\n",
    "                metric_list = metric_list / len(db_val)\n",
    "                for class_i in range(num_classes-1):\n",
    "                    writer.add_scalar('info/val_{}_dice'.format(class_i+1), metric_list[class_i, 0], iter_num)\n",
    "                    writer.add_scalar('info/val_{}_hd95'.format(class_i+1), metric_list[class_i, 1], iter_num)\n",
    "\n",
    "                performance = np.mean(metric_list, axis=0)[0]\n",
    "                writer.add_scalar('info/val_mean_dice', performance, iter_num)\n",
    "\n",
    "                if performance > best_performance:\n",
    "                    best_performance = performance\n",
    "                    save_mode_path = os.path.join(snapshot_path, 'iter_{}_dice_{}.pth'.format(iter_num, round(best_performance, 4)))\n",
    "                    save_best_path = os.path.join(snapshot_path,'{}_best_model.pth'.format(args.model))\n",
    "                    save_net_opt(model, optimizer, save_mode_path)\n",
    "                    save_net_opt(model, optimizer, save_best_path)\n",
    "\n",
    "                logging.info('iteration %d : mean_dice : %f' % (iter_num, performance))\n",
    "                model.train()\n",
    "\n",
    "            if iter_num >= max_iterations:\n",
    "                break\n",
    "        if iter_num >= max_iterations:\n",
    "            iterator.close()\n",
    "            break\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c29e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selftrain(args, pretrain_snapshot_path, snapshot_path): \n",
    "    # Extract params\n",
    "    base_lr = args.base_lr\n",
    "    num_classes = args.num_classes\n",
    "    max_iterations = args.selftrain_iterations\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu \n",
    "    pretrained_model = os.path.join(pretrain_snapshot_path, f'{args.model}_best_model.pth')\n",
    "    labeled_bs = args.labeled_bs\n",
    "    labeled_sub_bs, unlabeled_sub_bs = int(args.labeled_bs / 2), int((args.batch_size - args.labeled_bs) /2 )\n",
    "\n",
    "    # Load data \n",
    "    def worker_init_fn(worker_id): \n",
    "        random.seed(args.seed + worker_id)\n",
    "\n",
    "    db_train = ACDCDataset(base_dir= args.root_dir, split= 'train', \n",
    "                        transform= transforms.Compose([RandomGenerator(args.patch_size)]))\n",
    "    db_val = ACDCDataset(base_dir= args.root_dir, split= 'val')\n",
    "    total_slices = len(db_train)\n",
    "    labeled_slices = ACDC_patients_to_slices(args.root_dir, args.label_num)\n",
    "    print(f'Total slices: {total_slices}, Labeled slices: {labeled_slices}')\n",
    "    labeled_idxs = list(range(0, labeled_slices))\n",
    "    unlabeled_idxs = list(range(labeled_slices, total_slices))\n",
    "    batch_sampler = TwoStreamBatchSampler(labeled_idxs, unlabeled_idxs, args.batch_size, args.batch_size - args.labeled_bs)\n",
    "    trainloader = DataLoader(db_train, batch_sampler= batch_sampler, num_workers= 4, pin_memory= True)\n",
    "    valloader = DataLoader(db_val, batch_size= 1, shuffle= False, num_workers= 1)\n",
    "\n",
    "    # Model \n",
    "    model = BCP_net(in_chns=1, num_classes= 4)\n",
    "    ema_model = BCP_net(in_chns= 1, num_classes= 4, ema= True)\n",
    "    optimizer = optim.SGD(model.parameters(), lr= base_lr, momentum= 0.9, weight_decay= 1e-4)\n",
    "    load_net(ema_model, pretrained_model)\n",
    "    load_net_opt(model, optimizer, pretrained_model)\n",
    "    logging.info(f'Loaded from {pretrained_model}')\n",
    "    writer = SummaryWriter(snapshot_path + '/log')\n",
    "    logging.info('Start self-training')\n",
    "    logging.info(f'{len(trainloader)} iterations per epoch')\n",
    "\n",
    "    model.train() \n",
    "    ema_model.train() \n",
    "    iter_num = 0 \n",
    "    max_epoch = max_iterations // len(trainloader) + 1 \n",
    "    best_performance = 0.0 \n",
    "    best_hd = 100.0 \n",
    "    iterator = tqdm(range(0, max_epoch), ncols= 70)\n",
    "    for _ in iterator: \n",
    "        for _, sampled_batch in enumerate(trainloader): \n",
    "            volume_batch, label_batch = sampled_batch['image'], sampled_batch['label']\n",
    "            volume_batch, label_batch = volume_batch.cuda(), label_batch.cuda() \n",
    "\n",
    "            # BCP augmentation \n",
    "            img_a, img_b = volume_batch[: labeled_sub_bs], volume_batch[labeled_sub_bs : labeled_bs]\n",
    "            lab_a, lab_b = label_batch[: labeled_sub_bs], label_batch[labeled_sub_bs : labeled_bs]\n",
    "            uimg_a, uimg_b = volume_batch[labeled_bs : labeled_bs + unlabeled_sub_bs], volume_batch[labeled_bs + unlabeled_sub_bs :]\n",
    "            ulab_a, ulab_b = label_batch[labeled_bs : labeled_bs + unlabeled_sub_bs], label_batch[labeled_bs + unlabeled_sub_bs :]\n",
    "            with torch.no_grad(): \n",
    "                pre_a = ema_model(uimg_a, mode = 'seg')\n",
    "                pre_b = ema_model(uimg_b, mode = 'seg')\n",
    "                plab_a = get_ACDC_masks(pre_a, nms= 1)\n",
    "                plab_b = get_ACDC_masks(pre_b, nms= 1)\n",
    "                img_mask, loss_mask = generate_mask(img_a)\n",
    "                unl_label = plab_a * img_mask + lab_a * (1 - img_mask) # TODO: Problem !! \n",
    "                l_label = lab_b * img_mask + plab_b * (1 - img_mask) #TODO: Problem !!! \n",
    "            consistency_weight = get_current_consistency_weight(args, iter_num // 150) # ADJUST\n",
    "            # ---------------------- Segmentation ----------------------------------- # \n",
    "            net_input_unl = uimg_a * img_mask + img_a * ( 1 - img_mask)\n",
    "            net_input_l = img_b * img_mask + uimg_b * (1 - img_mask)\n",
    "            out_unl = model(net_input_unl, mode='seg')\n",
    "            out_l = model(net_input_l, mode='seg')\n",
    "            unl_dice, unl_ce = mix_loss(out_unl, plab_a, lab_a, loss_mask, u_weight= args.u_weight, unlab= True)\n",
    "            l_dice, l_ce = mix_loss(out_l, lab_b, plab_b, loss_mask, u_weight= args.u_weight)\n",
    "\n",
    "            loss_ce = unl_ce + l_ce \n",
    "            loss_dice = unl_dice + l_dice \n",
    "            loss_bcp = (loss_ce + loss_dice) / 2 \n",
    "            # ----------------------------------- Reconstruction task --------------------------------- # \n",
    "            masked_img, mask = mask_image(volume_batch, block_size= 5, mask_ratio= 0.5)\n",
    "            masked_img = masked_img.cuda() \n",
    "            mask = mask.cuda() \n",
    "            \n",
    "            out_recon =  model(masked_img, mode = 'recon')\n",
    "            rec_loss = reconstruction_loss(out_recon, volume_batch, mask)\n",
    "            \n",
    "            # --------------------------------------- Backward -------------------------------------  # \n",
    "            loss = args.bcp_weight * loss_bcp \n",
    "            optimizer.zero_grad() \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            iter_num += 1 \n",
    "            update_model_ema(model, ema_model, 0.99)\n",
    "\n",
    "            writer.add_scalar('info/total_loss', loss, iter_num)\n",
    "            writer.add_scalar('info/mix_dice', loss_dice, iter_num)\n",
    "            writer.add_scalar('info/mix_ce', loss_ce, iter_num)\n",
    "            writer.add_scalar('info/consistency_weight', consistency_weight, iter_num)   \n",
    "            # writer.add_scalar('info/recon_loss', rec_loss.item(), iter_num)\n",
    "            # logging.info(f'iteration: {iter_num}, mix_dice: {loss_dice}, mix_ce: {loss_ce}, rec_loss: {rec_loss}')\n",
    "                \n",
    "            if iter_num % 20 == 0:\n",
    "                # Compare the reconstruct task \n",
    "                gt_image = volume_batch[1, 0:1].detach().cpu()\n",
    "                gt_image = (gt_image - gt_image.min()) / (gt_image.max() - gt_image.min())\n",
    "                writer.add_image('train/Reconstruction_GT', gt_image, iter_num)\n",
    "\n",
    "                # recon_image = out_recon[1, 0:1].detach().cpu()\n",
    "                # recon_image = (recon_image - recon_image.min()) / (recon_image.max() - recon_image.min() + 1e-5)\n",
    "                # writer.add_image('train/Reconstruction', recon_image, iter_num)\n",
    "\n",
    "                image = net_input_unl[1, 0:1, :, :]\n",
    "                writer.add_image('train/Un_Image', image, iter_num)\n",
    "                outputs = torch.argmax(torch.softmax(out_unl, dim=1), dim=1, keepdim=True)\n",
    "                writer.add_image('train/Un_Prediction', outputs[1, ...] * 50, iter_num)\n",
    "                labs = unl_label[1, ...].unsqueeze(0) * 50\n",
    "                writer.add_image('train/Un_GroundTruth', labs, iter_num)\n",
    "\n",
    "                image_l = net_input_l[1, 0:1, :, :]\n",
    "                writer.add_image('train/L_Image', image_l, iter_num)\n",
    "                outputs_l = torch.argmax(torch.softmax(out_l, dim=1), dim=1, keepdim=True)\n",
    "                writer.add_image('train/L_Prediction', outputs_l[1, ...] * 50, iter_num)\n",
    "                labs_l = l_label[1, ...].unsqueeze(0) * 50\n",
    "                writer.add_image('train/L_GroundTruth', labs_l, iter_num)\n",
    "\n",
    "            if iter_num > 0 and iter_num % 200 == 0:\n",
    "                model.eval()\n",
    "                metric_list = 0.0\n",
    "                for _, sampled_batch in enumerate(valloader):\n",
    "                    metric_i = test_single_volume(sampled_batch[\"image\"], sampled_batch[\"label\"], model, classes=num_classes)\n",
    "                    metric_list += np.array(metric_i)\n",
    "                metric_list = metric_list / len(db_val)\n",
    "                for class_i in range(num_classes-1):\n",
    "                    writer.add_scalar('info/val_{}_dice'.format(class_i+1), metric_list[class_i, 0], iter_num)\n",
    "                    writer.add_scalar('info/val_{}_hd95'.format(class_i+1), metric_list[class_i, 1], iter_num)\n",
    "\n",
    "                performance = np.mean(metric_list, axis=0)[0]\n",
    "                writer.add_scalar('info/val_mean_dice', performance, iter_num)\n",
    "\n",
    "                if performance > best_performance:\n",
    "                    best_performance = performance\n",
    "                    save_mode_path = os.path.join(snapshot_path, 'iter_{}_dice_{}.pth'.format(iter_num, round(best_performance, 4)))\n",
    "                    save_best_path = os.path.join(snapshot_path,'{}_best_model.pth'.format(args.model))\n",
    "                    torch.save(model.state_dict(), save_mode_path)\n",
    "                    torch.save(model.state_dict(), save_best_path)\n",
    "\n",
    "                logging.info('iteration %d : mean_dice : %f' % (iter_num, performance))\n",
    "                model.train()\n",
    "\n",
    "            if iter_num >= max_iterations:\n",
    "                break\n",
    "        if iter_num >= max_iterations:\n",
    "            iterator.close()\n",
    "            break\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ef0509",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_snapshot_path = 'modelBCP/pretrain'\n",
    "selftrain_snapshot_path = 'modelBCP/selftrain'\n",
    "for snapshot in [pretrain_snapshot_path, selftrain_snapshot_path]: \n",
    "    os.makedirs(snapshot, exist_ok= True)\n",
    "\n",
    "for handler in logging.root.handlers[:]: \n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename= 'modelBCP/log.txt',\n",
    "    level= logging.INFO, \n",
    "    format= '[%(asctime)s] %(message)s', \n",
    "    datefmt= '%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "# Log out configuration \n",
    "logging.info(\"========== Experiment Configuration ==========\")\n",
    "logging.info(f\"Pretrain Iterations  : {args.pretrain_iterations}\")\n",
    "logging.info(f\"Selftrain Iterations : {args.selftrain_iterations}\")\n",
    "logging.info(f\"Batch Size           : {args.batch_size}\")\n",
    "logging.info(f\"Labeled Batch Size   : {args.labeled_bs}\")\n",
    "logging.info(f\"Labelled Patients    : {args.label_num}\")\n",
    "logging.info(f\"Learning Rate        : {args.base_lr}\")\n",
    "logging.info(f\"Patch Size           : {args.patch_size}\")\n",
    "logging.info(f\"BCP Weight           : {args.bcp_weight}\")\n",
    "logging.info(f\"Reconstruction Weight: {args.recon_weight}\")\n",
    "logging.info(\"==============================================\")\n",
    "\n",
    "pretrain(args, pretrain_snapshot_path)\n",
    "selftrain(args, pretrain_snapshot_path, selftrain_snapshot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396d59ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
