{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d235d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9675135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-22 22:19:24.089056: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-22 22:19:24.103038: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-22 22:19:24.106813: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-22 22:19:24.118160: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-22 22:19:25.110339: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import logging\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "\n",
    "# module \n",
    "from networks.net_factory import BCP_net\n",
    "from dataset.basedataset import ACDCDataset\n",
    "from dataset.utils import RandomGenerator, ACDC_patients_to_slices, TwoStreamBatchSampler\n",
    "from utils.params import params \n",
    "from utils.masks import generate_mask, random_mask, contact_mask\n",
    "from utils.losses import mix_loss\n",
    "from utils.valid2d import test_single_volume\n",
    "from networks.utils import save_net_opt, load_net_opt, load_net\n",
    "\n",
    "\n",
    "# writer \n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eaf1ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = params() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41399da2",
   "metadata": {},
   "source": [
    "#### 1. BCP network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f5859cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-train BCP\n",
    "def pretrain(args, snapshot_path): \n",
    "    base_lr = args.base_lr\n",
    "    num_classes = args.num_classes\n",
    "    max_iterations = args.pretrain_iterations\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu \n",
    "    labeled_bs = args.labeled_bs \n",
    "\n",
    "    # Load data \n",
    "    def worker_init_fn(worker_id):\n",
    "        random.seed(args.seed + worker_id) \n",
    "\n",
    "    label_sub_bs, unlabeled_sub_bs = int(args.labeled_bs / 2), int((args.batch_size - args.labeled_bs)/2) \n",
    "    db_train = ACDCDataset(base_dir= args.root_dir, split= 'train', \n",
    "                        transform= transforms.Compose([RandomGenerator(args.patch_size)]))\n",
    "    db_val = ACDCDataset(base_dir= args.root_dir, split= 'val')\n",
    "    total_slices = len(db_train)\n",
    "    labeled_slices = ACDC_patients_to_slices(args.root_dir, args.label_num)\n",
    "    print(f'Total slices is: {total_slices}, labeled slices is: {labeled_slices}')\n",
    "    labeled_idxes = list(range(0, labeled_slices))\n",
    "    unlabeled_idxes = list(range(labeled_slices, total_slices))\n",
    "    batch_sampler = TwoStreamBatchSampler(labeled_idxes, unlabeled_idxes, args.batch_size, args.batch_size - args.labeled_bs)\n",
    "\n",
    "    trainloader = DataLoader(db_train, batch_sampler= batch_sampler, num_workers= 4, pin_memory= True, worker_init_fn= worker_init_fn)\n",
    "    valloader = DataLoader(db_val, batch_size=1, shuffle= False, num_workers= 1)\n",
    "\n",
    "    # Model \n",
    "    model = BCP_net(in_chns=1, num_classes= num_classes)\n",
    "    optimizer = optim.SGD(model.parameters(), lr= base_lr, momentum= 0.9, weight_decay= 0.0001)\n",
    "\n",
    "    writer = SummaryWriter(snapshot_path + '/log')\n",
    "    logging.info('Start pre_training')\n",
    "    logging.info(f'{len(trainloader)} iterations per epoch')\n",
    "\n",
    "    model.train() \n",
    "    iter_num = 0 \n",
    "    max_epoch = max_iterations // len(trainloader) + 1 \n",
    "    best_performance = 0.0 \n",
    "    best_hd = 100 \n",
    "    iterator = tqdm(range(max_epoch), ncols= 70) \n",
    "    for _ in iterator: \n",
    "        for _, sampled_batch in enumerate(trainloader): \n",
    "            volume_batch, label_batch = sampled_batch['image'], sampled_batch['label']\n",
    "            volume_batch, label_batch = volume_batch.cuda(), label_batch.cuda() \n",
    "\n",
    "            # Create BCP image \n",
    "            img_a, img_b = volume_batch[: label_sub_bs], volume_batch[label_sub_bs : labeled_bs]\n",
    "            lab_a, lab_b = label_batch[: label_sub_bs], label_batch[label_sub_bs: labeled_bs]\n",
    "            img_mask, loss_mask =  generate_mask(img_a)\n",
    "            gt_mixl = lab_a * img_mask + lab_b * (1 - img_mask)\n",
    "\n",
    "            # Feed to model \n",
    "            net_input = img_a * img_mask + img_b * (1 - img_mask)\n",
    "            out_mixl = model(net_input)\n",
    "            loss_dice, loss_ce = mix_loss(out_mixl, lab_a, lab_b, loss_mask, u_weight= 1.0, unlab= True)\n",
    "\n",
    "            loss = (loss_dice + loss_ce ) / 2 \n",
    "            optimizer.zero_grad() \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            iter_num += 1 \n",
    "\n",
    "            writer.add_scalar('info/total loss', loss, iter_num)\n",
    "            writer.add_scalar('info/mix_dice', loss_dice, iter_num)\n",
    "            writer.add_scalar('info/mix_ce', loss_ce, iter_num)\n",
    "\n",
    "            logging.info(f'iteration: {iter_num}, loss: {loss}, mix_dice: {loss_dice}, mix_ce: {loss_ce}')\n",
    "            if iter_num % 20 == 0:\n",
    "                image = net_input[1, 0:1, :, :]  # shape = [1, H, W]\n",
    "                image = (image - image.min()) / (image.max() - image.min() + 1e-5)  # normalize to [0,1]\n",
    "                writer.add_image('pre_train/Mixed_Image', image, iter_num)\n",
    "                outputs = torch.argmax(torch.softmax(out_mixl, dim=1), dim=1, keepdim=True)\n",
    "                writer.add_image('pre_train/Mixed_Prediction', outputs[1, ...] * 50, iter_num)\n",
    "                labs = gt_mixl[1, ...].unsqueeze(0) * 50\n",
    "                writer.add_image('pre_train/Mixed_GroundTruth', labs, iter_num)\n",
    "\n",
    "            if iter_num > 0 and iter_num % 200 == 0:\n",
    "                model.eval()\n",
    "                metric_list = 0.0\n",
    "                for _, sampled_batch in enumerate(valloader):\n",
    "                    metric_i = test_single_volume(sampled_batch[\"image\"], sampled_batch[\"label\"], model, classes=num_classes)\n",
    "                    metric_list += np.array(metric_i)\n",
    "                metric_list = metric_list / len(db_val)\n",
    "                for class_i in range(num_classes-1):\n",
    "                    writer.add_scalar('info/val_{}_dice'.format(class_i+1), metric_list[class_i, 0], iter_num)\n",
    "                    writer.add_scalar('info/val_{}_hd95'.format(class_i+1), metric_list[class_i, 1], iter_num)\n",
    "\n",
    "                performance = np.mean(metric_list, axis=0)[0]\n",
    "                writer.add_scalar('info/val_mean_dice', performance, iter_num)\n",
    "\n",
    "                if performance > best_performance:\n",
    "                    best_performance = performance\n",
    "                    save_mode_path = os.path.join(snapshot_path, 'iter_{}_dice_{}.pth'.format(iter_num, round(best_performance, 4)))\n",
    "                    save_best_path = os.path.join(snapshot_path,'{}_best_model.pth'.format(args.model))\n",
    "                    save_net_opt(model, optimizer, save_mode_path)\n",
    "                    save_net_opt(model, optimizer, save_best_path)\n",
    "\n",
    "                logging.info('iteration %d : mean_dice : %f' % (iter_num, performance))\n",
    "                model.train()\n",
    "\n",
    "            if iter_num >= max_iterations:\n",
    "                break\n",
    "        if iter_num >= max_iterations:\n",
    "            iterator.close()\n",
    "            break\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c29e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selftrain(args, pretrain_snapshot_path, selftrain_snapshot_path): \n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48ef0509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: train: 1312 samples in total\n",
      "Mode: val: 20 samples in total\n",
      "Total slices is: 1312, labeled slices is: 136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|██████████████████████████████▊| 181/182 [03:22<00:01,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "pretrain_snapshot_path = 'modelBCP/pretrain'\n",
    "selftrain_snapshot_path = 'modelBCP/selftrain'\n",
    "for snapshot in [pretrain_snapshot_path, selftrain_snapshot_path]: \n",
    "    os.makedirs(snapshot, exist_ok= True)\n",
    "\n",
    "for handler in logging.root.handlers[:]: \n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename= 'modelBCP/log.txt',\n",
    "    level= logging.INFO, \n",
    "    format= '[%(asctime)s] %(message)s', \n",
    "    datefmt= '%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "pretrain(args, pretrain_snapshot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396d59ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
