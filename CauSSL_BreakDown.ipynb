{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import random \n",
    "import time \n",
    "import logging \n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import torch \n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "from utils.params import params \n",
    "from utils.losses import DiceLoss, softmax_mse_loss, softmax_kl_loss, l_correlation_cos_mean\n",
    "from networks.utils import BCP_net, get_current_consistency_weight, update_ema_variable\n",
    "from dataset.basedataset import BaseDataset\n",
    "from dataset.utils import TwoStreamBatchSampler, RandomGenerator, patients_to_slices\n",
    "\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear Cofficient (Gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_vector(nn.Module): \n",
    "    \"\"\"\n",
    "    Create linear cofficients (Gb) respect to the weight in UNet \n",
    "    \"\"\"\n",
    "    def __init__(self, n_dim): \n",
    "        super(Linear_vector, self).__init__() \n",
    "        self.n_dim = n_dim \n",
    "        self.params = Parameter(torch.Tensor(self.n_dim, self.n_dim))\n",
    "        self.init_ratio = 1e-3\n",
    "        self.initialize() \n",
    "    \n",
    "    def initialize(self): \n",
    "        for param in self.params: \n",
    "            param.data.normal_(0, self.init_ratio)\n",
    "        \n",
    "    \n",
    "    def forward(self, x): \n",
    "        result = torch.mm(self.params, x) \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where it use \n",
    "model = BCP_net(in_chns=1, class_num= 4) \n",
    "\n",
    "linear_coffies1 = []\n",
    "linear_coffies2 = [] \n",
    "for name, parameter in model.named_parameters(): \n",
    "    if 'conv' in name and 'weight' in name: \n",
    "        if len(parameter.shape) == 4: \n",
    "            out_dim = parameter.shape[0] # output channel \n",
    "            linear_coffies1.append(Linear_vector(out_dim))\n",
    "            linear_coffies2.append(Linear_vector(out_dim))\n",
    "\n",
    "# Convert to torch \n",
    "linear_coffies1 = nn.ModuleList(linear_coffies1)\n",
    "linear_coffies2 = nn.ModuleList(linear_coffies2)\n",
    "linear_coffies1 = linear_coffies1.cuda()\n",
    "linear_coffies2 = linear_coffies2.cuda() \n",
    "\n",
    "# create optimizer for them \n",
    "linear_optimizer1 = torch.optim.Adam(linear_coffies1.parameters(), 2e-2)\n",
    "linear_optimizer2 = torch.optim.Adam(linear_coffies2.parameters(), 2e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Loss function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Supervised = CE + Dice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BCP_net(in_chns=1, class_num= 4) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
