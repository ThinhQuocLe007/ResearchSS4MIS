{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T11:05:00.061442Z",
     "iopub.status.busy": "2024-12-13T11:05:00.061054Z",
     "iopub.status.idle": "2024-12-13T11:05:00.068602Z",
     "shell.execute_reply": "2024-12-13T11:05:00.067562Z",
     "shell.execute_reply.started": "2024-12-13T11:05:00.061401Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import h5py\n",
    "import os \n",
    "import random \n",
    "import itertools\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from torch.optim import SGD\n",
    "import torchvision.transforms as transforms\n",
    "from skimage.measure import label \n",
    "\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T11:05:00.070934Z",
     "iopub.status.busy": "2024-12-13T11:05:00.070429Z",
     "iopub.status.idle": "2024-12-13T11:05:08.269610Z",
     "shell.execute_reply": "2024-12-13T11:05:08.268621Z",
     "shell.execute_reply.started": "2024-12-13T11:05:00.070891Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: medpy in /home/lequocthinh/miniconda3/envs/DeepLearning/lib/python3.12/site-packages (0.5.2)\n",
      "Requirement already satisfied: scipy>=1.10 in /home/lequocthinh/miniconda3/envs/DeepLearning/lib/python3.12/site-packages (from medpy) (1.14.1)\n",
      "Requirement already satisfied: numpy>=1.24 in /home/lequocthinh/miniconda3/envs/DeepLearning/lib/python3.12/site-packages (from medpy) (1.26.4)\n",
      "Requirement already satisfied: SimpleITK>=2.1 in /home/lequocthinh/miniconda3/envs/DeepLearning/lib/python3.12/site-packages (from medpy) (2.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install medpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T11:05:08.272133Z",
     "iopub.status.busy": "2024-12-13T11:05:08.271793Z",
     "iopub.status.idle": "2024-12-13T11:05:08.277278Z",
     "shell.execute_reply": "2024-12-13T11:05:08.276416Z",
     "shell.execute_reply.started": "2024-12-13T11:05:08.272103Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import shutil\n",
    "import argparse\n",
    "import logging\n",
    "import random\n",
    "from medpy import metric\n",
    "import pdb\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params \n",
    "class params: \n",
    "    def __init__(self):\n",
    "        self.root_path = 'LA'\n",
    "        self.exp = 'BCP' \n",
    "        self.model = 'VNet'\n",
    "        self.pre_max_iterations = 20\n",
    "        self.self_max_iteration = 10 \n",
    "        self.max_samples = 80 \n",
    "        self.labeled_bs = 4\n",
    "        self.batch_size = 8 \n",
    "        self.base_lr = 0.01 \n",
    "        self.deterministic = 1 \n",
    "        self.labelnum = 8 \n",
    "        self.consistency = 1.0 \n",
    "        self.consistency_rampup = 40.0 \n",
    "        self.magnitude = 10.0 \n",
    "        self.seed = 10\n",
    "        self.gpu = '0'\n",
    "    \n",
    "        # Setting of BCP \n",
    "        self.u_weight = 0.5 \n",
    "        self.mask_ratio = 2/3 \n",
    "\n",
    "        # Setting of mixup \n",
    "        self.u_alpha = 2.0 \n",
    "        self.loss_weight = 0.5\n",
    "\n",
    "\n",
    "args = params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. BaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T11:05:08.290717Z",
     "iopub.status.busy": "2024-12-13T11:05:08.290442Z",
     "iopub.status.idle": "2024-12-13T11:05:08.303834Z",
     "shell.execute_reply": "2024-12-13T11:05:08.303179Z",
     "shell.execute_reply.started": "2024-12-13T11:05:08.290692Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class LAHeart(Dataset):\n",
    "    def __init__(self, base_dir, split='train', transform=None, num=None):\n",
    "        self._base_dir = base_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.sample_list = []\n",
    "        \n",
    "        # Path for train/test list\n",
    "        list_file = os.path.join(self._base_dir, f\"{split}.list\")\n",
    "        if not os.path.isfile(list_file):\n",
    "            raise ValueError(f\"The {split} list file is missing: {list_file}\")\n",
    "        \n",
    "        with open(list_file, 'r') as file:\n",
    "            self.sample_list = [item.strip() for item in file.readlines()]\n",
    "        \n",
    "        if num is not None:\n",
    "            self.sample_list = self.sample_list[:num]\n",
    "\n",
    "        print(f\"Mode = {self.split}, total samples: {len(self.sample_list)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        case = self.sample_list[index]\n",
    "        file_path = os.path.join(self._base_dir, f'2018LA_Seg_Training Set/{case}/mri_norm2.h5')\n",
    "        \n",
    "        # Load data safely\n",
    "        try:\n",
    "            with h5py.File(file_path, 'r') as h5f:\n",
    "                image = h5f['image'][:]\n",
    "                label = h5f['label'][:]\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "        \n",
    "        sample = {'image': image, 'label': label}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T11:05:08.435002Z",
     "iopub.status.busy": "2024-12-13T11:05:08.434625Z",
     "iopub.status.idle": "2024-12-13T11:05:08.440972Z",
     "shell.execute_reply": "2024-12-13T11:05:08.440088Z",
     "shell.execute_reply.started": "2024-12-13T11:05:08.434963Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def random_rot_flip(image, label): \n",
    "    k = np.random.randint(0, 4, 1) \n",
    "    image = np.rot90(image, k) \n",
    "    label = np.rot90(label, k) \n",
    "\n",
    "    axis = np.random.randint(0, 2)\n",
    "    image = np.flip(image, axis) \n",
    "    label = np.flip(label, axis) \n",
    "\n",
    "    return image, label \n",
    "\n",
    "class RandomRotFlip: \n",
    "    def __call__(self, sample): \n",
    "        image, label = sample['image'], sample['label']\n",
    "        image, label = random_rot_flip(image, label) \n",
    "        sample = {'image': image, 'label': label}\n",
    "\n",
    "        return sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T11:05:08.442226Z",
     "iopub.status.busy": "2024-12-13T11:05:08.441984Z",
     "iopub.status.idle": "2024-12-13T11:05:08.457774Z",
     "shell.execute_reply": "2024-12-13T11:05:08.457016Z",
     "shell.execute_reply.started": "2024-12-13T11:05:08.442201Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RandomCrop: \n",
    "    def __init__(self, output_size, with_sdf= False): \n",
    "        self.output_size = output_size \n",
    "        self.with_sdf = with_sdf\n",
    "    \n",
    "    def __call__(self, sample): \n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        if self.with_sdf: \n",
    "            sdf = sample['sdf']\n",
    "        \n",
    "        if label.shape[0] <= self.output_size[0] or label.shape[1] <= self.output_size[1] or label.shape[2] <= self.output_size[2]: \n",
    "            pw = max((self.output_size[0] - label.shape[0]) // 2 + 3, 0) \n",
    "            ph = max((self.output_size[1] - label.shape[1]) // 2 + 3, 0)\n",
    "            pd = max((self.output_size[2] - label.shape[2]) // 2 + 3, 0)\n",
    "            image = np.pad(image, [(pw, pw), (ph, ph),(pd, pd)], mode= 'constant', constant_values= 0)\n",
    "            label = np.pad(label, [(pw, pw), (ph, ph), (pd, pd)], mode= 'constant', constant_values= 0) \n",
    "\n",
    "            if self.with_sdf: \n",
    "                sdf = np.pad(sdf, [(pw, pw), (ph, ph), (pd, pd)], mode= 'constant', constant_values= 0) \n",
    "\n",
    "        (w, h,d) = image.shape \n",
    "        w1 = np.random.randint(0, w - self.output_size[0])\n",
    "        h1 = np.random.randint(0, h - self.output_size[1])\n",
    "        d1 = np.random.randint(0, d - self.output_size[2])\n",
    "    \n",
    "        image = image[w1 : w1 + self.output_size[0], h1 : h1 + self.output_size[1], d1 : d1 + self.output_size[2]]\n",
    "        label = label[w1: w1 + self.output_size[0], h1 : h1 + self.output_size[1], d1 : d1 + self.output_size[2]]\n",
    "\n",
    "        if self.with_sdf: \n",
    "            sdf = sdf[w1 : w1 + self.output_size[0], h1 : h1 + self.output_size[1], d1 : d1 + self.output_size[2]]\n",
    "            return {'image': image, 'label': label, 'sdf': sdf}\n",
    "        else: \n",
    "            return {'image': image, 'label': label}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T11:05:08.458962Z",
     "iopub.status.busy": "2024-12-13T11:05:08.458691Z",
     "iopub.status.idle": "2024-12-13T11:05:08.471825Z",
     "shell.execute_reply": "2024-12-13T11:05:08.471106Z",
     "shell.execute_reply.started": "2024-12-13T11:05:08.458937Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        image = sample['image'].copy()\n",
    "        label = sample['label'].copy()\n",
    "        \n",
    "        # Ensure the image is reshaped correctly and avoid negative strides by copying the array\n",
    "        image = image.reshape(1, image.shape[0], image.shape[1], image.shape[2]).astype(np.float32)\n",
    "        \n",
    "        if 'onehot_label' in sample:\n",
    "            return {\n",
    "                'image': torch.from_numpy(image),\n",
    "                'label': torch.from_numpy(sample['label']).long(),\n",
    "                'onehot_label': torch.from_numpy(sample['onehot_label']).long()\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'image': torch.from_numpy(image),\n",
    "                'label': torch.from_numpy(label).long()\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T11:05:08.472940Z",
     "iopub.status.busy": "2024-12-13T11:05:08.472657Z",
     "iopub.status.idle": "2024-12-13T11:05:08.485159Z",
     "shell.execute_reply": "2024-12-13T11:05:08.484332Z",
     "shell.execute_reply.started": "2024-12-13T11:05:08.472914Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def iterate_once(indices): \n",
    "    \"\"\"\n",
    "    Permutate the iterable once \n",
    "    (permutate the labeled_idxs once)\n",
    "    \"\"\"\n",
    "    return np.random.permutation(indices) \n",
    "\n",
    "def iterate_externally(indices): \n",
    "    \"\"\"\n",
    "    Create an infinite iterator that repeatedly permutes the indices.\n",
    "    ( permutate the unlabeled_idxs to make different)\n",
    "    \"\"\"\n",
    "    def infinite_shuffles(): \n",
    "        while True: \n",
    "            yield np.random.permutation(indices)\n",
    "            \n",
    "    return itertools.chain.from_iterable(infinite_shuffles())\n",
    "\n",
    "def grouper(iterable, n): \n",
    "    args = [iter(iterable)] * n \n",
    "    return zip(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T11:05:08.487650Z",
     "iopub.status.busy": "2024-12-13T11:05:08.487426Z",
     "iopub.status.idle": "2024-12-13T11:05:08.496142Z",
     "shell.execute_reply": "2024-12-13T11:05:08.495223Z",
     "shell.execute_reply.started": "2024-12-13T11:05:08.487627Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TwoStreamBatchSampler(Sampler):\n",
    "    def __init__(self, primary_indices, secondary_indices, batch_size, secondary_batch_size):\n",
    "        self.primary_indices = primary_indices\n",
    "        self.secondary_indices = secondary_indices\n",
    "        self.primary_batch_size = batch_size - secondary_batch_size\n",
    "        self.secondary_batch_size = secondary_batch_size\n",
    "        \n",
    "        assert len(self.primary_indices) >= self.primary_batch_size > 0\n",
    "        assert len(self.secondary_indices) >= self.secondary_batch_size > 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        primary_iter = iterate_once(self.primary_indices)\n",
    "        secondary_iter = iterate_externally(self.secondary_indices)\n",
    "        return (\n",
    "            primary_batch + secondary_batch\n",
    "            for (primary_batch, secondary_batch)\n",
    "            in zip(grouper(primary_iter, self.primary_batch_size),\n",
    "                   grouper(secondary_iter, self.secondary_batch_size))\n",
    "        )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.primary_indices) // self.primary_batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T11:05:08.497968Z",
     "iopub.status.busy": "2024-12-13T11:05:08.497197Z",
     "iopub.status.idle": "2024-12-13T11:05:08.509711Z",
     "shell.execute_reply": "2024-12-13T11:05:08.508903Z",
     "shell.execute_reply.started": "2024-12-13T11:05:08.497925Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def context_mask(img, mask_ratio):\n",
    "    batch_size, channel, img_x, img_y, img_z = img.shape[0], img.shape[1], img.shape[2], img.shape[3], img.shape[4]\n",
    "    loss_mask = torch.ones(batch_size, img_x, img_y, img_z).cuda()\n",
    "    mask = torch.ones(img_x, img_y, img_z).cuda()\n",
    "    patch_pixel_x, patch_pixel_y, patch_pixel_z = int(img_x*mask_ratio), int(img_y*mask_ratio), int(img_z*mask_ratio)\n",
    "    w = np.random.randint(0, 112 - patch_pixel_x)\n",
    "    h = np.random.randint(0, 112 - patch_pixel_y)\n",
    "    z = np.random.randint(0, 80 - patch_pixel_z)\n",
    "    mask[w:w+patch_pixel_x, h:h+patch_pixel_y, z:z+patch_pixel_z] = 0\n",
    "    loss_mask[:, w:w+patch_pixel_x, h:h+patch_pixel_y, z:z+patch_pixel_z] = 0\n",
    "    return mask.long(), loss_mask.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T11:05:08.530776Z",
     "iopub.status.busy": "2024-12-13T11:05:08.530491Z",
     "iopub.status.idle": "2024-12-13T11:05:08.545439Z",
     "shell.execute_reply": "2024-12-13T11:05:08.544731Z",
     "shell.execute_reply.started": "2024-12-13T11:05:08.530750Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def to_one_hot(tensor, nclasses): \n",
    "    \"\"\"\n",
    "    Input (tensor): Nx1xHxW \n",
    "    \"\"\"\n",
    "    assert tensor.max().item() < nclasses\n",
    "    assert tensor.min().item() >= 0 \n",
    "\n",
    "    size = list(tensor.size())\n",
    "    assert size[1] == 1 \n",
    "    size[1] = nclasses\n",
    "    one_hot = torch.zeros(*size) \n",
    "    if tensor.is_cuda: \n",
    "        one_hot = one_hot.cuda(tensor.device) \n",
    "    one_hot = one_hot.scatter_(1, tensor, 1) \n",
    "    return one_hot \n",
    "\n",
    "def get_probability(logits): \n",
    "    \"\"\"\n",
    "    Get the probability from logitis  \n",
    "    \"\"\"\n",
    "    size = logits.size() \n",
    "    if size[1] > 1: \n",
    "        pred = F.softmax(logits, dim= 1) \n",
    "        nclass = size[1] \n",
    "    else: \n",
    "        pred = F.sigmoid(logits) \n",
    "        pred = torch.cat([1 - pred, pred], dim= 1) \n",
    "    \n",
    "    return pred, nclass\n",
    "\n",
    "\n",
    "class mask_DiceLoss(nn.Module): \n",
    "    def __init__(self, nclass, class_weights = None, smooth= 1e-5): \n",
    "        super(mask_DiceLoss, self).__init__() \n",
    "        self.smooth = smooth \n",
    "        if class_weights is None: \n",
    "            self.class_weights = nn.Parameter(torch.ones((1, nclass)).type(torch.float32), requires_grad= False) \n",
    "        else: \n",
    "            class_weights = np.array(class_weights) \n",
    "            assert nclass == class_weights.shape[0] \n",
    "            self.class_weights = nn.Parameter(torch.tensor(class_weights, dtype= torch.float32), requires_grad= False) \n",
    "    \n",
    "    def prob_forward(self, pred, target, mask= None): \n",
    "        size = pred.size() \n",
    "        N, nclass = size[0], size[1] \n",
    "\n",
    "        # N x C x H x W: convert into 2D image\n",
    "        pred_one_hot = pred.view(N, nclass, -1) \n",
    "        target = target.view(N, 1, -1) \n",
    "        target_one_hot = to_one_hot(target.type(torch.long), nclass).type(torch.float32)\n",
    "\n",
    "        # N x C x H x W\n",
    "        inter = pred_one_hot * target_one_hot\n",
    "        union = pred_one_hot + target_one_hot\n",
    "\n",
    "        if mask is not None: \n",
    "            mask = mask.view(N, 1, -1) \n",
    "            inter = (inter.view(N, nclass, -1) * mask).sum(2) \n",
    "            union = (union.view(N, nclass, -1) * mask).sum(2) \n",
    "        else: \n",
    "            inter = inter.view(N, nclass, -1).sum(2) \n",
    "            union = union.view(N, nclass, -1).sum(2)\n",
    "        \n",
    "        dice = ( 2*inter + self.smooth ) / (union + self.smooth) \n",
    "        return 1 - dice.mean()\n",
    "\n",
    "    def forward(self, logits,target, mask = None): \n",
    "        size = logits.size() \n",
    "        N, nclass = size[0], size[1] \n",
    "\n",
    "        logits = logits.view(N, nclass, -1) \n",
    "        target = target.view(N, 1, -1) \n",
    "\n",
    "        pred, nclass = get_probability(logits) \n",
    "\n",
    "        pred_one_hot = pred \n",
    "        target_one_hot = to_one_hot(target.type(torch.long), nclass).type(torch.float32) \n",
    "\n",
    "        inter = pred_one_hot * target_one_hot\n",
    "        union = pred_one_hot + target_one_hot\n",
    "\n",
    "        if mask is not None: \n",
    "            mask = mask.view(N, 1, -1) \n",
    "            inter = (inter.view(N, nclass, -1) * mask).sum(2)\n",
    "            union = (union.view(N, nclass, -1) * mask ).sum(2) \n",
    "        else: \n",
    "            inter = inter.view(N, nclass, -1).sum(2) \n",
    "            union = union.view(N, nclass, -1).sum(2)\n",
    "        \n",
    "        dice = ( 2 * inter + self.smooth ) / (union + self.smooth)\n",
    "        return 1 - dice.mean() \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICE  = mask_DiceLoss(nclass= 2)\n",
    "CE = nn.CrossEntropyLoss()\n",
    "def mix_loss(net3_output, img_l, patch_l, mask, l_weight=1.0, u_weight=0.5, unlab=False):\n",
    "    img_l, patch_l = img_l.type(torch.int64), patch_l.type(torch.int64)\n",
    "    image_weight, patch_weight = l_weight, u_weight\n",
    "    if unlab:\n",
    "        image_weight, patch_weight = u_weight, l_weight\n",
    "    patch_mask = 1 - mask\n",
    "    dice_loss = DICE(net3_output, img_l, mask) * image_weight \n",
    "    dice_loss += DICE(net3_output, patch_l, patch_mask) * patch_weight\n",
    "    loss_ce = image_weight * (CE(net3_output, img_l) * mask).sum() / (mask.sum() + 1e-16) \n",
    "    loss_ce += patch_weight * (CE(net3_output, patch_l) * patch_mask).sum() / (patch_mask.sum() + 1e-16)\n",
    "    loss = (dice_loss + loss_ce) / 2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Validaion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_case(model, image, stride_xy, stride_z, patch_size, num_classes=1):\n",
    "    w, h, d = image.shape\n",
    "\n",
    "    # if the size of image is less than patch_size, then padding it\n",
    "    add_pad = False\n",
    "    if w < patch_size[0]:\n",
    "        w_pad = patch_size[0]-w\n",
    "        add_pad = True\n",
    "    else:\n",
    "        w_pad = 0\n",
    "    if h < patch_size[1]:\n",
    "        h_pad = patch_size[1]-h\n",
    "        add_pad = True\n",
    "    else:\n",
    "        h_pad = 0\n",
    "    if d < patch_size[2]:\n",
    "        d_pad = patch_size[2]-d\n",
    "        add_pad = True\n",
    "    else:\n",
    "        d_pad = 0\n",
    "    wl_pad, wr_pad = w_pad//2,w_pad-w_pad//2\n",
    "    hl_pad, hr_pad = h_pad//2,h_pad-h_pad//2\n",
    "    dl_pad, dr_pad = d_pad//2,d_pad-d_pad//2\n",
    "    if add_pad:\n",
    "        image = np.pad(image, [(wl_pad,wr_pad),(hl_pad,hr_pad), (dl_pad, dr_pad)], mode='constant', constant_values=0)\n",
    "    ww,hh,dd = image.shape\n",
    "\n",
    "    sx = math.ceil((ww - patch_size[0]) / stride_xy) + 1\n",
    "    sy = math.ceil((hh - patch_size[1]) / stride_xy) + 1\n",
    "    sz = math.ceil((dd - patch_size[2]) / stride_z) + 1\n",
    "    # print(\"{}, {}, {}\".format(sx, sy, sz))\n",
    "    score_map = np.zeros((num_classes, ) + image.shape).astype(np.float32)\n",
    "    cnt = np.zeros(image.shape).astype(np.float32)\n",
    "\n",
    "    for x in range(0, sx):\n",
    "        xs = min(stride_xy*x, ww-patch_size[0])\n",
    "        for y in range(0, sy):\n",
    "            ys = min(stride_xy * y,hh-patch_size[1])\n",
    "            for z in range(0, sz):\n",
    "                zs = min(stride_z * z, dd-patch_size[2])\n",
    "                test_patch = image[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]]\n",
    "                test_patch = np.expand_dims(np.expand_dims(test_patch,axis=0),axis=0).astype(np.float32)\n",
    "                test_patch = torch.from_numpy(test_patch).cuda()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    y1, _ = model(test_patch)\n",
    "                    y = F.softmax(y1, dim=1)\n",
    "\n",
    "                y = y.cpu().data.numpy()\n",
    "                y = y[0,1,:,:,:]\n",
    "                score_map[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] \\\n",
    "                  = score_map[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] + y\n",
    "                cnt[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] \\\n",
    "                  = cnt[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] + 1\n",
    "    score_map = score_map/np.expand_dims(cnt,axis=0)\n",
    "    label_map = (score_map[0]>0.5).astype(np.int32)\n",
    "    if add_pad:\n",
    "        label_map = label_map[wl_pad:wl_pad+w,hl_pad:hl_pad+h,dl_pad:dl_pad+d]\n",
    "        score_map = score_map[:,wl_pad:wl_pad+w,hl_pad:hl_pad+h,dl_pad:dl_pad+d]\n",
    "    return label_map, score_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_all_case_LA(model, num_classes, patch_size=(112, 112, 80), stride_xy=18, stride_z=4):\n",
    "    file_path = 'LA/test.list'\n",
    "    with open(file_path, 'r') as f:\n",
    "        image_list = f.readlines()\n",
    "    \n",
    "    folder_dir = 'LA/2018LA_Seg_Training Set/'\n",
    "    image_list = [folder_dir + item.replace('\\n', '') + \"/mri_norm2.h5\" for item in image_list]\n",
    "    loader = tqdm(image_list)\n",
    "    total_dice = 0.0\n",
    "    for image_path in loader:\n",
    "        h5f = h5py.File(image_path, 'r')\n",
    "        image = h5f['image'][:]\n",
    "        label = h5f['label'][:]\n",
    "        prediction, score_map = test_single_case(model, image, stride_xy, stride_z, patch_size, num_classes=num_classes)\n",
    "        if np.sum(prediction)==0:\n",
    "            dice = 0\n",
    "        else:\n",
    "            dice = metric.binary.dc(prediction, label)\n",
    "        total_dice += dice\n",
    "    avg_dice = total_dice / len(image_list)\n",
    "    print('average metric is {}'.format(avg_dice))\n",
    "    return avg_dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.VNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T11:05:08.547037Z",
     "iopub.status.busy": "2024-12-13T11:05:08.546693Z",
     "iopub.status.idle": "2024-12-13T11:05:08.584822Z",
     "shell.execute_reply": "2024-12-13T11:05:08.583903Z",
     "shell.execute_reply.started": "2024-12-13T11:05:08.547000Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, n_stages, n_filters_in, n_filters_out, kernel_size=3, padding=1, normalization='none'):\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        ops = []\n",
    "        for i in range(n_stages):\n",
    "            if i==0:\n",
    "                input_channel = n_filters_in\n",
    "            else:\n",
    "                input_channel = n_filters_out\n",
    "\n",
    "            ops.append(nn.Conv3d(input_channel, n_filters_out, kernel_size=kernel_size, padding=padding))\n",
    "            if normalization == 'batchnorm':\n",
    "                ops.append(nn.BatchNorm3d(n_filters_out))\n",
    "            elif normalization == 'groupnorm':\n",
    "                ops.append(nn.GroupNorm(num_groups=16, num_channels=n_filters_out))\n",
    "            elif normalization == 'instancenorm':\n",
    "                ops.append(nn.InstanceNorm3d(n_filters_out))\n",
    "            elif normalization != 'none':\n",
    "                assert False\n",
    "            ops.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        self.conv = nn.Sequential(*ops)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResidualConvBlock(nn.Module):\n",
    "    def __init__(self, n_stages, n_filters_in, n_filters_out, normalization='none'):\n",
    "        super(ResidualConvBlock, self).__init__()\n",
    "\n",
    "        ops = []\n",
    "        for i in range(n_stages):\n",
    "            if i == 0:\n",
    "                input_channel = n_filters_in\n",
    "            else:\n",
    "                input_channel = n_filters_out\n",
    "\n",
    "            ops.append(nn.Conv3d(input_channel, n_filters_out, 3, padding=1))\n",
    "            if normalization == 'batchnorm':\n",
    "                ops.append(nn.BatchNorm3d(n_filters_out))\n",
    "            elif normalization == 'groupnorm':\n",
    "                ops.append(nn.GroupNorm(num_groups=16, num_channels=n_filters_out))\n",
    "            elif normalization == 'instancenorm':\n",
    "                ops.append(nn.InstanceNorm3d(n_filters_out))\n",
    "            elif normalization != 'none':\n",
    "                assert False\n",
    "\n",
    "            if i != n_stages-1:\n",
    "                ops.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        self.conv = nn.Sequential(*ops)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = (self.conv(x) + x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DownsamplingConvBlock(nn.Module):\n",
    "    def __init__(self, n_filters_in, n_filters_out, stride=2, padding=0, normalization='none'):\n",
    "        super(DownsamplingConvBlock, self).__init__()\n",
    "\n",
    "        ops = []\n",
    "        if normalization != 'none':\n",
    "            ops.append(nn.Conv3d(n_filters_in, n_filters_out, stride, padding=padding, stride=stride))\n",
    "            if normalization == 'batchnorm':\n",
    "                ops.append(nn.BatchNorm3d(n_filters_out))\n",
    "            elif normalization == 'groupnorm':\n",
    "                ops.append(nn.GroupNorm(num_groups=16, num_channels=n_filters_out))\n",
    "            elif normalization == 'instancenorm':\n",
    "                ops.append(nn.InstanceNorm3d(n_filters_out))\n",
    "            else:\n",
    "                assert False\n",
    "        else:\n",
    "            ops.append(nn.Conv3d(n_filters_in, n_filters_out, stride, padding=padding, stride=stride))\n",
    "\n",
    "        ops.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        self.conv = nn.Sequential(*ops)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UpsamplingDeconvBlock(nn.Module):\n",
    "    def __init__(self, n_filters_in, n_filters_out, stride=2, padding=0,normalization='none'):\n",
    "        super(UpsamplingDeconvBlock, self).__init__()\n",
    "\n",
    "        ops = []\n",
    "        if normalization != 'none':\n",
    "            ops.append(nn.ConvTranspose3d(n_filters_in, n_filters_out, stride, padding=padding, stride=stride))\n",
    "            if normalization == 'batchnorm':\n",
    "                ops.append(nn.BatchNorm3d(n_filters_out))\n",
    "            elif normalization == 'groupnorm':\n",
    "                ops.append(nn.GroupNorm(num_groups=16, num_channels=n_filters_out))\n",
    "            elif normalization == 'instancenorm':\n",
    "                ops.append(nn.InstanceNorm3d(n_filters_out))\n",
    "            else:\n",
    "                assert False\n",
    "        else:\n",
    "            ops.append(nn.ConvTranspose3d(n_filters_in, n_filters_out, stride, padding=padding, stride=stride))\n",
    "\n",
    "        ops.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        self.conv = nn.Sequential(*ops)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class Upsampling(nn.Module):\n",
    "    def __init__(self, n_filters_in, n_filters_out, stride=2, normalization='none'):\n",
    "        super(Upsampling, self).__init__()\n",
    "\n",
    "        ops = []\n",
    "        ops.append(nn.Upsample(scale_factor=stride, mode=\"trilinear\",align_corners=False))\n",
    "        ops.append(nn.Conv3d(n_filters_in, n_filters_out, kernel_size=3, padding=1))\n",
    "        if normalization == 'batchnorm':\n",
    "            ops.append(nn.BatchNorm3d(n_filters_out))\n",
    "        elif normalization == 'groupnorm':\n",
    "            ops.append(nn.GroupNorm(num_groups=16, num_channels=n_filters_out))\n",
    "        elif normalization == 'instancenorm':\n",
    "            ops.append(nn.InstanceNorm3d(n_filters_out))\n",
    "        elif normalization != 'none':\n",
    "            assert False\n",
    "        ops.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        self.conv = nn.Sequential(*ops)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_channels=3, n_classes=2, n_filters=16, normalization='none', has_dropout=False, has_residual=False):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.has_dropout = has_dropout\n",
    "        convBlock = ConvBlock if not has_residual else ResidualConvBlock\n",
    "\n",
    "        self.block_one = convBlock(1, n_channels, n_filters, normalization=normalization)\n",
    "        self.block_one_dw = DownsamplingConvBlock(n_filters, 2 * n_filters, normalization=normalization)\n",
    "\n",
    "        self.block_two = convBlock(2, n_filters * 2, n_filters * 2, normalization=normalization)\n",
    "        self.block_two_dw = DownsamplingConvBlock(n_filters * 2, n_filters * 4, normalization=normalization)\n",
    "\n",
    "        self.block_three = convBlock(3, n_filters * 4, n_filters * 4, normalization=normalization)\n",
    "        self.block_three_dw = DownsamplingConvBlock(n_filters * 4, n_filters * 8, normalization=normalization)\n",
    "\n",
    "        self.block_four = convBlock(3, n_filters * 8, n_filters * 8, normalization=normalization)\n",
    "        self.block_four_dw = DownsamplingConvBlock(n_filters * 8, n_filters * 16, normalization=normalization)\n",
    "\n",
    "        self.block_five = convBlock(3, n_filters * 16, n_filters * 16, normalization=normalization)\n",
    "        \n",
    "        self.dropout = nn.Dropout3d(p=0.5, inplace=False)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x1 = self.block_one(input)\n",
    "        x1_dw = self.block_one_dw(x1)\n",
    "\n",
    "        x2 = self.block_two(x1_dw)\n",
    "        x2_dw = self.block_two_dw(x2)\n",
    "\n",
    "        x3 = self.block_three(x2_dw)\n",
    "        x3_dw = self.block_three_dw(x3)\n",
    "\n",
    "        x4 = self.block_four(x3_dw)\n",
    "        x4_dw = self.block_four_dw(x4)\n",
    "\n",
    "        x5 = self.block_five(x4_dw)\n",
    "\n",
    "        if self.has_dropout:\n",
    "            x5 = self.dropout(x5)\n",
    "\n",
    "        res = [x1, x2, x3, x4, x5]\n",
    "        return res\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_channels=3, n_classes=2, n_filters=16, normalization='none', has_dropout=False, has_residual=False):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.has_dropout = has_dropout\n",
    "\n",
    "        convBlock = ConvBlock if not has_residual else ResidualConvBlock\n",
    "\n",
    "        upsampling = UpsamplingDeconvBlock ## using transposed convolution\n",
    "\n",
    "        self.block_five_up = upsampling(n_filters * 16, n_filters * 8, normalization=normalization)\n",
    "\n",
    "        self.block_six = convBlock(3, n_filters * 8, n_filters * 8, normalization=normalization)\n",
    "        self.block_six_up = upsampling(n_filters * 8, n_filters * 4, normalization=normalization)\n",
    "\n",
    "        self.block_seven = convBlock(3, n_filters * 4, n_filters * 4, normalization=normalization)\n",
    "        self.block_seven_up = upsampling(n_filters * 4, n_filters * 2, normalization=normalization)\n",
    "\n",
    "        self.block_eight = convBlock(2, n_filters * 2, n_filters * 2, normalization=normalization)\n",
    "        self.block_eight_up = upsampling(n_filters * 2, n_filters, normalization=normalization)\n",
    "\n",
    "        self.block_nine = convBlock(1, n_filters, n_filters, normalization=normalization)\n",
    "        self.out_conv = nn.Conv3d(n_filters, n_classes, 1, padding=0)\n",
    "        self.dropout = nn.Dropout3d(p=0.5, inplace=False)\n",
    "\n",
    "    def forward(self, features):\n",
    "        x1 = features[0]\n",
    "        x2 = features[1]\n",
    "        x3 = features[2]\n",
    "        x4 = features[3]\n",
    "        x5 = features[4]\n",
    "        \n",
    "        x5_up = self.block_five_up(x5)\n",
    "        x5_up = x5_up + x4\n",
    "\n",
    "        x6 = self.block_six(x5_up)\n",
    "        x6_up = self.block_six_up(x6)\n",
    "        x6_up = x6_up + x3\n",
    "\n",
    "        x7 = self.block_seven(x6_up)\n",
    "        x7_up = self.block_seven_up(x7)\n",
    "        x7_up = x7_up + x2\n",
    "\n",
    "        x8 = self.block_eight(x7_up)\n",
    "        x8_up = self.block_eight_up(x8)\n",
    "        x8_up = x8_up + x1\n",
    "        x9 = self.block_nine(x8_up)\n",
    "        # x9 = F.dropout3d(x9, p=0.5, training=True)\n",
    "        if self.has_dropout:\n",
    "            x9 = self.dropout(x9)\n",
    "        out_seg = self.out_conv(x9)\n",
    "        return out_seg, x8_up\n",
    " \n",
    "class VNet(nn.Module):\n",
    "    def __init__(self, n_channels=3, n_classes=2, n_filters=16, normalization='none', has_dropout=False, has_residual=False):\n",
    "        super(VNet, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(n_channels, n_classes, n_filters, normalization, has_dropout, has_residual)\n",
    "        self.decoder = Decoder(n_channels, n_classes, n_filters, normalization, has_dropout, has_residual)\n",
    "        dim_in = 16\n",
    "        feat_dim = 32\n",
    "        self.pool = nn.MaxPool3d(3, stride=2)\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(dim_in, feat_dim),\n",
    "            nn.BatchNorm1d(feat_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(feat_dim, feat_dim)\n",
    "        )\n",
    "        self.prediction_head = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim),\n",
    "            nn.BatchNorm1d(feat_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(feat_dim, feat_dim)\n",
    "        )\n",
    "        for class_c in range(2):\n",
    "            selector = nn.Sequential(\n",
    "                nn.Linear(feat_dim, feat_dim),\n",
    "                nn.BatchNorm1d(feat_dim),\n",
    "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "                nn.Linear(feat_dim, 1)\n",
    "            )\n",
    "            self.__setattr__('contrastive_class_selector_' + str(class_c), selector)\n",
    "\n",
    "        for class_c in range(2):\n",
    "            selector = nn.Sequential(\n",
    "                nn.Linear(feat_dim, feat_dim),\n",
    "                nn.BatchNorm1d(feat_dim),\n",
    "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "                nn.Linear(feat_dim, 1)\n",
    "            )\n",
    "            self.__setattr__('contrastive_class_selector_memory' + str(class_c), selector)\n",
    "        \n",
    "    def forward_projection_head(self, features):\n",
    "        return self.projection_head(features)\n",
    "\n",
    "    def forward_prediction_head(self, features):\n",
    "        return self.prediction_head(features)\n",
    "\n",
    "    def forward(self, input):\n",
    "        features = self.encoder(input)\n",
    "        out_seg, x8_up = self.decoder(features)\n",
    "        features = self.pool(features[4])\n",
    "        return out_seg, features # 4, 16, 112, 112, 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T11:05:08.586336Z",
     "iopub.status.busy": "2024-12-13T11:05:08.586057Z",
     "iopub.status.idle": "2024-12-13T11:05:08.598173Z",
     "shell.execute_reply": "2024-12-13T11:05:08.597340Z",
     "shell.execute_reply.started": "2024-12-13T11:05:08.586309Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_rampup(current, rampup_length):\n",
    "    if rampup_length == 0: \n",
    "        return 1.0 \n",
    "    else:\n",
    "        current = np.clip(current, 0, rampup_length)\n",
    "        phase = 1 - (current / rampup_length)\n",
    "        return float(np.exp(-5 * phase * phase))\n",
    "    \n",
    "# Mean-Teacher compomnent \n",
    "def get_current_consistency_weight(epoch, args): \n",
    "    return 5 * args.consistency + sigmoid_rampup(epoch, args.consistency_rampup)\n",
    "\n",
    "@torch.no_grad()\n",
    "def update_ema_variables(model, ema_model, alpha):\n",
    "    for ema_param, param in zip(ema_model.parameters(), model.parameters()):\n",
    "        ema_param.data.mul_(alpha).add_((1 - alpha) * param.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T11:05:08.599352Z",
     "iopub.status.busy": "2024-12-13T11:05:08.599098Z",
     "iopub.status.idle": "2024-12-13T11:05:08.612258Z",
     "shell.execute_reply": "2024-12-13T11:05:08.611537Z",
     "shell.execute_reply.started": "2024-12-13T11:05:08.599327Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_cut_mask(out, thres=0.5, nms=0):\n",
    "    probs = F.softmax(out, 1)\n",
    "    masks = (probs >= thres).type(torch.int64)\n",
    "    masks = masks[:, 1, :, :].contiguous()\n",
    "    if nms == 1:\n",
    "        masks = LargestCC_pancreas(masks)\n",
    "    return masks\n",
    "\n",
    "def LargestCC_pancreas(segmentation):\n",
    "    N = segmentation.shape[0]\n",
    "    batch_list = []\n",
    "    for n in range(N):\n",
    "        n_prob = segmentation[n].detach().cpu().numpy()\n",
    "        labels = label(n_prob)\n",
    "        if labels.max() != 0:\n",
    "            largestCC = labels == np.argmax(np.bincount(labels.flat)[1:])+1\n",
    "        else:\n",
    "            largestCC = n_prob\n",
    "        batch_list.append(largestCC)\n",
    "    \n",
    "    return torch.Tensor(batch_list).cuda()\n",
    "\n",
    "def save_net_opt(net, optimizer, path):\n",
    "    state = {\n",
    "        'net': net.state_dict(),\n",
    "        'opt': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(state, str(path))\n",
    "\n",
    "def load_net_opt(net, optimizer, path):\n",
    "    state = torch.load(str(path))\n",
    "    net.load_state_dict(state['net'])\n",
    "    optimizer.load_state_dict(state['opt'])\n",
    "\n",
    "def load_net(net, path):\n",
    "    state = torch.load(str(path))\n",
    "    net.load_state_dict(state['net'])\n",
    "\n",
    "def get_current_consistency_weight(epoch):\n",
    "    return args.consistency * sigmoid_rampup(epoch, args.consistency_rampup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T11:05:08.613912Z",
     "iopub.status.busy": "2024-12-13T11:05:08.613541Z",
     "iopub.status.idle": "2024-12-13T11:05:08.622072Z",
     "shell.execute_reply": "2024-12-13T11:05:08.621240Z",
     "shell.execute_reply.started": "2024-12-13T11:05:08.613872Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def net_factory(net_type=\"Unet\", in_channels=1, class_num=2, mode=\"train\", tsne=0):\n",
    "    if net_type == \"VNet\" and mode == \"train\" and tsne==0:\n",
    "        net = VNet(n_channels=in_channels, n_classes=class_num, normalization='batchnorm', has_dropout=True).cuda()\n",
    "        \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = args.root_path \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu \n",
    "pre_max_iterations = args.pre_max_iterations\n",
    "self_max_iterations = args.self_max_iteration \n",
    "base_lr = args.base_lr \n",
    "CE = nn.CrossEntropyLoss(reduction= 'none')\n",
    "\n",
    "if args.deterministic:\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "\n",
    "patch_size = (112, 112, 80)\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T11:05:08.640872Z",
     "iopub.status.busy": "2024-12-13T11:05:08.640503Z",
     "iopub.status.idle": "2024-12-13T11:05:08.652586Z",
     "shell.execute_reply": "2024-12-13T11:05:08.651820Z",
     "shell.execute_reply.started": "2024-12-13T11:05:08.640815Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def pre_train(args, snapshot_path):\n",
    "    model = net_factory(args.model, in_channels=1, class_num=num_classes, mode=\"train\")\n",
    "    db_train = LAHeart(base_dir=train_data_path, \n",
    "                       split='train',\n",
    "                       transform=transforms.Compose([\n",
    "                           RandomRotFlip(),\n",
    "                           RandomCrop(patch_size),\n",
    "                           ToTensor(),\n",
    "                       ]))\n",
    "    labelnum = args.labelnum\n",
    "    labeled_idxs = list(range(labelnum))\n",
    "    unlabeled_idxs = list(range(labelnum, args.max_samples))\n",
    "    batch_sampler = TwoStreamBatchSampler(labeled_idxs, unlabeled_idxs, args.batch_size, args.batch_size-args.labeled_bs)\n",
    "    sub_bs = int(args.labeled_bs/2)\n",
    "    def worker_init_fn(worker_id):\n",
    "        random.seed(args.seed+worker_id)\n",
    "    trainloader = DataLoader(db_train, batch_sampler=batch_sampler, num_workers=4, pin_memory=True, worker_init_fn=worker_init_fn)\n",
    "    optimizer = SGD(model.parameters(), lr=base_lr, momentum=0.9, weight_decay=1e-4)\n",
    "    DICE = mask_DiceLoss(nclass=2)\n",
    "    \n",
    "    model.train()\n",
    "    writer = SummaryWriter(snapshot_path + '/log')\n",
    "    logging.info(\"{} iterations per epoch\".format(len(trainloader)))\n",
    "    iter_num = 0\n",
    "    best_dice = 0\n",
    "    max_epoch = pre_max_iterations // len(trainloader) + 1\n",
    "    iterator = tqdm(range(max_epoch), ncols=70)\n",
    "    for epoch_num in iterator:\n",
    "        for _, sampled_batch in enumerate(trainloader):\n",
    "            volume_batch, label_batch = sampled_batch['image'][:args.labeled_bs], sampled_batch['label'][:args.labeled_bs]\n",
    "            volume_batch, label_batch = volume_batch.cuda(), label_batch.cuda()\n",
    "            img_a, img_b = volume_batch[:sub_bs], volume_batch[sub_bs:]\n",
    "            lab_a, lab_b = label_batch[:sub_bs], label_batch[sub_bs:]\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                img_mask, loss_mask = context_mask(img_a, args.mask_ratio)\n",
    "                \n",
    "            # Mix Input\n",
    "            volume_batch = img_a * img_mask + img_b * (1 - img_mask)\n",
    "            label_batch = lab_a * img_mask + lab_b * (1 - img_mask)\n",
    "            \n",
    "            outputs, _ = model(volume_batch)\n",
    "            loss_ce = F.cross_entropy(outputs, label_batch)\n",
    "            loss_dice = DICE(outputs, label_batch)\n",
    "            loss = (loss_ce + loss_dice) / 2\n",
    "            \n",
    "            iter_num += 1\n",
    "            writer.add_scalar('pre/loss_dice', loss_dice, iter_num)\n",
    "            writer.add_scalar('pre/loss_ce', loss_ce, iter_num)\n",
    "            writer.add_scalar('pre/loss_all', loss, iter_num)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            logging.info('iteration %d : loss: %03f, loss_dice: %03f, loss_ce: %03f' %(iter_num, loss, loss_dice, loss_ce))\n",
    "\n",
    "            if iter_num % 20 == 0:\n",
    "                model.eval()\n",
    "                dice_sample = var_all_case_LA(model, num_classes=num_classes, patch_size=patch_size, stride_xy=18, stride_z=4)\n",
    "                if dice_sample > best_dice:\n",
    "                    best_dice = round(dice_sample, 4)\n",
    "                    save_mode_path = os.path.join(snapshot_path,  'iter_{}_dice_{}.pth'.format(iter_num, best_dice))\n",
    "                    save_best_path = os.path.join(snapshot_path,'{}_best_model.pth'.format(args.model))\n",
    "                    save_net_opt(model, optimizer, save_mode_path)\n",
    "                    save_net_opt(model, optimizer, save_best_path)\n",
    "                    # torch.save(model.state_dict(), save_mode_path)\n",
    "                    # torch.save(model.state_dict(), save_best_path)\n",
    "                    logging.info(\"save best model to {}\".format(save_mode_path))\n",
    "                writer.add_scalar('4_Var_dice/Dice', dice_sample, iter_num)\n",
    "                writer.add_scalar('4_Var_dice/Best_dice', best_dice, iter_num)\n",
    "                model.train()\n",
    "\n",
    "            \n",
    "            if iter_num >= pre_max_iterations:\n",
    "                break\n",
    "\n",
    "        if iter_num >= pre_max_iterations:\n",
    "            iterator.close()\n",
    "            break\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_train(args, pre_snapshot_path, self_snapshot_path):\n",
    "    model = net_factory(net_type=args.model, in_channels=1, class_num=num_classes, mode=\"train\")\n",
    "    ema_model = net_factory(net_type=args.model, in_channels=1, class_num=num_classes, mode=\"train\")\n",
    "    for param in ema_model.parameters():\n",
    "            param.detach_()   # ema_model set\n",
    "    db_train = LAHeart(base_dir=train_data_path,\n",
    "                       split='train',\n",
    "                       transform = transforms.Compose([\n",
    "                          RandomRotFlip(),\n",
    "                          RandomCrop(patch_size),\n",
    "                          ToTensor(),\n",
    "                          ]))\n",
    "    labelnum = args.labelnum\n",
    "    labeled_idxs = list(range(labelnum))\n",
    "    unlabeled_idxs = list(range(labelnum, args.max_samples))\n",
    "    batch_sampler = TwoStreamBatchSampler(labeled_idxs, unlabeled_idxs, args.batch_size, args.batch_size-args.labeled_bs)\n",
    "    sub_bs = int(args.labeled_bs/2)\n",
    "    def worker_init_fn(worker_id):\n",
    "        random.seed(args.seed+worker_id)\n",
    "    trainloader = DataLoader(db_train, batch_sampler=batch_sampler, num_workers=4, pin_memory=True, worker_init_fn=worker_init_fn)\n",
    "    optimizer = SGD(model.parameters(), lr=base_lr, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "    pretrained_model = os.path.join(pre_snapshot_path, f'{args.model}_best_model.pth')\n",
    "    load_net(model, pretrained_model)\n",
    "    load_net(ema_model, pretrained_model)\n",
    "    \n",
    "    model.train()\n",
    "    ema_model.train()\n",
    "    writer = SummaryWriter(self_snapshot_path+'/log')\n",
    "    logging.info(\"{} iterations per epoch\".format(len(trainloader)))\n",
    "    iter_num = 0\n",
    "    best_dice = 0\n",
    "    max_epoch = self_max_iterations // len(trainloader) + 1\n",
    "    lr_ = base_lr\n",
    "    iterator = tqdm(range(max_epoch), ncols=70)\n",
    "    for epoch in iterator:\n",
    "        for _, sampled_batch in enumerate(trainloader):\n",
    "            volume_batch, label_batch = sampled_batch['image'], sampled_batch['label']\n",
    "            volume_batch, label_batch = volume_batch.cuda(), label_batch.cuda()\n",
    "            img_a, img_b = volume_batch[:sub_bs], volume_batch[sub_bs:args.labeled_bs]\n",
    "            lab_a, lab_b = label_batch[:sub_bs], label_batch[sub_bs:args.labeled_bs]\n",
    "            unimg_a, unimg_b = volume_batch[args.labeled_bs:args.labeled_bs+sub_bs], volume_batch[args.labeled_bs+sub_bs:]\n",
    "            with torch.no_grad():\n",
    "                unoutput_a, _ = ema_model(unimg_a)\n",
    "                unoutput_b, _ = ema_model(unimg_b)\n",
    "                plab_a = get_cut_mask(unoutput_a, nms=1)\n",
    "                plab_b = get_cut_mask(unoutput_b, nms=1)\n",
    "                img_mask, loss_mask = context_mask(img_a, args.mask_ratio)\n",
    "            consistency_weight = get_current_consistency_weight(iter_num // 150)\n",
    "\n",
    "            mixl_img = img_a * img_mask + unimg_a * (1 - img_mask)\n",
    "            mixu_img = unimg_b * img_mask + img_b * (1 - img_mask)\n",
    "            mixl_lab = lab_a * img_mask + plab_a * (1 - img_mask)\n",
    "            mixu_lab = plab_b * img_mask + lab_b * (1 - img_mask)\n",
    "            outputs_l, _ = model(mixl_img)\n",
    "            outputs_u, _ = model(mixu_img)\n",
    "            loss_l = mix_loss(outputs_l, lab_a, plab_a, loss_mask, u_weight=args.u_weight)\n",
    "            loss_u = mix_loss(outputs_u, plab_b, lab_b, loss_mask, u_weight=args.u_weight, unlab=True)\n",
    "\n",
    "            loss = loss_l + loss_u\n",
    "\n",
    "            iter_num += 1\n",
    "            writer.add_scalar('Self/consistency', consistency_weight, iter_num)\n",
    "            writer.add_scalar('Self/loss_l', loss_l, iter_num)\n",
    "            writer.add_scalar('Self/loss_u', loss_u, iter_num)\n",
    "            writer.add_scalar('Self/loss_all', loss, iter_num)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            logging.info('iteration %d : loss: %03f, loss_l: %03f, loss_u: %03f'%(iter_num, loss, loss_l, loss_u))\n",
    "\n",
    "            update_ema_variables(model, ema_model, 0.99)\n",
    "\n",
    "             # change lr\n",
    "            if iter_num % 2500 == 0:\n",
    "                lr_ = base_lr * 0.1 ** (iter_num // 2500)\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = lr_\n",
    "\n",
    "            if iter_num % 200 == 0:\n",
    "                model.eval()\n",
    "                dice_sample = var_all_case_LA(model, num_classes=num_classes, patch_size=patch_size, stride_xy=18, stride_z=4)\n",
    "                if dice_sample > best_dice:\n",
    "                    best_dice = round(dice_sample, 4)\n",
    "                    save_mode_path = os.path.join(self_snapshot_path,  'iter_{}_dice_{}.pth'.format(iter_num, best_dice))\n",
    "                    save_best_path = os.path.join(self_snapshot_path,'{}_best_model.pth'.format(args.model))\n",
    "                    # save_net_opt(model, optimizer, save_mode_path)\n",
    "                    # save_net_opt(model, optimizer, save_best_path)\n",
    "                    torch.save(model.state_dict(), save_mode_path)\n",
    "                    torch.save(model.state_dict(), save_best_path)\n",
    "                    logging.info(\"save best model to {}\".format(save_mode_path))\n",
    "                writer.add_scalar('4_Var_dice/Dice', dice_sample, iter_num)\n",
    "                writer.add_scalar('4_Var_dice/Best_dice', best_dice, iter_num)\n",
    "                model.train()\n",
    "            \n",
    "            if iter_num % 200 == 1:\n",
    "                ins_width = 2\n",
    "                B,C,H,W,D = outputs_l.size()\n",
    "                snapshot_img = torch.zeros(size = (D, 3, 3*H + 3 * ins_width, W + ins_width), dtype = torch.float32)\n",
    "\n",
    "                snapshot_img[:,:, H:H+ ins_width,:] = 1\n",
    "                snapshot_img[:,:, 2*H + ins_width:2*H + 2*ins_width,:] = 1\n",
    "                snapshot_img[:,:, 3*H + 2*ins_width:3*H + 3*ins_width,:] = 1\n",
    "                snapshot_img[:,:, :,W:W+ins_width] = 1\n",
    "\n",
    "                outputs_l_soft = F.softmax(outputs_l, dim=1)\n",
    "                seg_out = outputs_l_soft[0,1,...].permute(2,0,1) # y\n",
    "                target =  mixl_lab[0,...].permute(2,0,1)\n",
    "                train_img = mixl_img[0,0,...].permute(2,0,1)\n",
    "\n",
    "                snapshot_img[:, 0,:H,:W] = (train_img-torch.min(train_img))/(torch.max(train_img)-torch.min(train_img))\n",
    "                snapshot_img[:, 1,:H,:W] = (train_img-torch.min(train_img))/(torch.max(train_img)-torch.min(train_img))\n",
    "                snapshot_img[:, 2,:H,:W] = (train_img-torch.min(train_img))/(torch.max(train_img)-torch.min(train_img))\n",
    "\n",
    "                snapshot_img[:, 0, H+ ins_width:2*H+ ins_width,:W] = target\n",
    "                snapshot_img[:, 1, H+ ins_width:2*H+ ins_width,:W] = target\n",
    "                snapshot_img[:, 2, H+ ins_width:2*H+ ins_width,:W] = target\n",
    "\n",
    "                snapshot_img[:, 0, 2*H+ 2*ins_width:3*H+ 2*ins_width,:W] = seg_out\n",
    "                snapshot_img[:, 1, 2*H+ 2*ins_width:3*H+ 2*ins_width,:W] = seg_out\n",
    "                snapshot_img[:, 2, 2*H+ 2*ins_width:3*H+ 2*ins_width,:W] = seg_out\n",
    "                \n",
    "                writer.add_images('Epoch_%d_Iter_%d_labeled'% (epoch, iter_num), snapshot_img)\n",
    "\n",
    "                outputs_u_soft = F.softmax(outputs_u, dim=1)\n",
    "                seg_out = outputs_u_soft[0,1,...].permute(2,0,1) # y\n",
    "                target =  mixu_lab[0,...].permute(2,0,1)\n",
    "                train_img = mixu_img[0,0,...].permute(2,0,1)\n",
    "\n",
    "                snapshot_img[:, 0,:H,:W] = (train_img-torch.min(train_img))/(torch.max(train_img)-torch.min(train_img))\n",
    "                snapshot_img[:, 1,:H,:W] = (train_img-torch.min(train_img))/(torch.max(train_img)-torch.min(train_img))\n",
    "                snapshot_img[:, 2,:H,:W] = (train_img-torch.min(train_img))/(torch.max(train_img)-torch.min(train_img))\n",
    "\n",
    "                snapshot_img[:, 0, H+ ins_width:2*H+ ins_width,:W] = target\n",
    "                snapshot_img[:, 1, H+ ins_width:2*H+ ins_width,:W] = target\n",
    "                snapshot_img[:, 2, H+ ins_width:2*H+ ins_width,:W] = target\n",
    "\n",
    "                snapshot_img[:, 0, 2*H+ 2*ins_width:3*H+ 2*ins_width,:W] = seg_out\n",
    "                snapshot_img[:, 1, 2*H+ 2*ins_width:3*H+ 2*ins_width,:W] = seg_out\n",
    "                snapshot_img[:, 2, 2*H+ 2*ins_width:3*H+ 2*ins_width,:W] = seg_out\n",
    "\n",
    "                writer.add_images('Epoch_%d_Iter_%d_unlabel'% (epoch, iter_num), snapshot_img)\n",
    "\n",
    "            if iter_num >= self_max_iterations:\n",
    "                break\n",
    "\n",
    "        if iter_num >= self_max_iterations:\n",
    "            iterator.close()\n",
    "            break\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T11:05:08.668920Z",
     "iopub.status.busy": "2024-12-13T11:05:08.668621Z",
     "iopub.status.idle": "2024-12-13T11:08:33.876794Z",
     "shell.execute_reply": "2024-12-13T11:08:33.875791Z",
     "shell.execute_reply.started": "2024-12-13T11:05:08.668874Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting BCP training.\n",
      "<__main__.params object at 0x7fa3f3728fb0>\n",
      "<__main__.params object at 0x7fa3f3728fb0>\n",
      "<__main__.params object at 0x7fa3f3728fb0>\n",
      "Mode = train, total samples: 80\n",
      "2 iterations per epoch\n",
      "2 iterations per epoch\n",
      "2 iterations per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 : loss: 0.680328, loss_dice: 0.582469, loss_ce: 0.778187\n",
      "iteration 1 : loss: 0.680328, loss_dice: 0.582469, loss_ce: 0.778187\n",
      "iteration 1 : loss: 0.680328, loss_dice: 0.582469, loss_ce: 0.778187\n",
      "iteration 2 : loss: 0.722332, loss_dice: 0.591725, loss_ce: 0.852940\n",
      "iteration 2 : loss: 0.722332, loss_dice: 0.591725, loss_ce: 0.852940\n",
      "iteration 2 : loss: 0.722332, loss_dice: 0.591725, loss_ce: 0.852940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|                               | 1/11 [00:00<00:09,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 3 : loss: 0.767395, loss_dice: 0.611944, loss_ce: 0.922847\n",
      "iteration 3 : loss: 0.767395, loss_dice: 0.611944, loss_ce: 0.922847\n",
      "iteration 3 : loss: 0.767395, loss_dice: 0.611944, loss_ce: 0.922847\n",
      "iteration 4 : loss: 0.709416, loss_dice: 0.590961, loss_ce: 0.827872\n",
      "iteration 4 : loss: 0.709416, loss_dice: 0.590961, loss_ce: 0.827872\n",
      "iteration 4 : loss: 0.709416, loss_dice: 0.590961, loss_ce: 0.827872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|                           | 2/11 [00:01<00:08,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 5 : loss: 0.656469, loss_dice: 0.576009, loss_ce: 0.736929\n",
      "iteration 5 : loss: 0.656469, loss_dice: 0.576009, loss_ce: 0.736929\n",
      "iteration 5 : loss: 0.656469, loss_dice: 0.576009, loss_ce: 0.736929\n",
      "iteration 6 : loss: 0.583871, loss_dice: 0.547771, loss_ce: 0.619971\n",
      "iteration 6 : loss: 0.583871, loss_dice: 0.547771, loss_ce: 0.619971\n",
      "iteration 6 : loss: 0.583871, loss_dice: 0.547771, loss_ce: 0.619971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|                        | 3/11 [00:03<00:08,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 7 : loss: 0.600334, loss_dice: 0.544235, loss_ce: 0.656432\n",
      "iteration 7 : loss: 0.600334, loss_dice: 0.544235, loss_ce: 0.656432\n",
      "iteration 7 : loss: 0.600334, loss_dice: 0.544235, loss_ce: 0.656432\n",
      "iteration 8 : loss: 0.600714, loss_dice: 0.548495, loss_ce: 0.652932\n",
      "iteration 8 : loss: 0.600714, loss_dice: 0.548495, loss_ce: 0.652932\n",
      "iteration 8 : loss: 0.600714, loss_dice: 0.548495, loss_ce: 0.652932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|                     | 4/11 [00:04<00:07,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 9 : loss: 0.517795, loss_dice: 0.526817, loss_ce: 0.508774\n",
      "iteration 9 : loss: 0.517795, loss_dice: 0.526817, loss_ce: 0.508774\n",
      "iteration 9 : loss: 0.517795, loss_dice: 0.526817, loss_ce: 0.508774\n",
      "iteration 10 : loss: 0.526468, loss_dice: 0.489687, loss_ce: 0.563248\n",
      "iteration 10 : loss: 0.526468, loss_dice: 0.489687, loss_ce: 0.563248\n",
      "iteration 10 : loss: 0.526468, loss_dice: 0.489687, loss_ce: 0.563248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|                  | 5/11 [00:04<00:05,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 11 : loss: 0.522497, loss_dice: 0.504972, loss_ce: 0.540022\n",
      "iteration 11 : loss: 0.522497, loss_dice: 0.504972, loss_ce: 0.540022\n",
      "iteration 11 : loss: 0.522497, loss_dice: 0.504972, loss_ce: 0.540022\n",
      "iteration 12 : loss: 0.529663, loss_dice: 0.532648, loss_ce: 0.526678\n",
      "iteration 12 : loss: 0.529663, loss_dice: 0.532648, loss_ce: 0.526678\n",
      "iteration 12 : loss: 0.529663, loss_dice: 0.532648, loss_ce: 0.526678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|               | 6/11 [00:05<00:04,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 13 : loss: 0.493981, loss_dice: 0.483166, loss_ce: 0.504795\n",
      "iteration 13 : loss: 0.493981, loss_dice: 0.483166, loss_ce: 0.504795\n",
      "iteration 13 : loss: 0.493981, loss_dice: 0.483166, loss_ce: 0.504795\n",
      "iteration 14 : loss: 0.472644, loss_dice: 0.478000, loss_ce: 0.467288\n",
      "iteration 14 : loss: 0.472644, loss_dice: 0.478000, loss_ce: 0.467288\n",
      "iteration 14 : loss: 0.472644, loss_dice: 0.478000, loss_ce: 0.467288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|            | 7/11 [00:06<00:03,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 15 : loss: 0.490905, loss_dice: 0.519590, loss_ce: 0.462219\n",
      "iteration 15 : loss: 0.490905, loss_dice: 0.519590, loss_ce: 0.462219\n",
      "iteration 15 : loss: 0.490905, loss_dice: 0.519590, loss_ce: 0.462219\n",
      "iteration 16 : loss: 0.390100, loss_dice: 0.437379, loss_ce: 0.342821\n",
      "iteration 16 : loss: 0.390100, loss_dice: 0.437379, loss_ce: 0.342821\n",
      "iteration 16 : loss: 0.390100, loss_dice: 0.437379, loss_ce: 0.342821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|         | 8/11 [00:07<00:02,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 17 : loss: 0.442462, loss_dice: 0.484468, loss_ce: 0.400456\n",
      "iteration 17 : loss: 0.442462, loss_dice: 0.484468, loss_ce: 0.400456\n",
      "iteration 17 : loss: 0.442462, loss_dice: 0.484468, loss_ce: 0.400456\n",
      "iteration 18 : loss: 0.471986, loss_dice: 0.502863, loss_ce: 0.441109\n",
      "iteration 18 : loss: 0.471986, loss_dice: 0.502863, loss_ce: 0.441109\n",
      "iteration 18 : loss: 0.471986, loss_dice: 0.502863, loss_ce: 0.441109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|      | 9/11 [00:08<00:01,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 19 : loss: 0.467744, loss_dice: 0.462164, loss_ce: 0.473325\n",
      "iteration 19 : loss: 0.467744, loss_dice: 0.462164, loss_ce: 0.473325\n",
      "iteration 19 : loss: 0.467744, loss_dice: 0.462164, loss_ce: 0.473325\n",
      "iteration 20 : loss: 0.460289, loss_dice: 0.493625, loss_ce: 0.426954\n",
      "iteration 20 : loss: 0.460289, loss_dice: 0.493625, loss_ce: 0.426954\n",
      "iteration 20 : loss: 0.460289, loss_dice: 0.493625, loss_ce: 0.426954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:35<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average metric is 0.07305181710129968\n",
      "save best model to ./model/BCP/LA_BCP_8_labeled/pre_train/iter_20_dice_0.0731.pth\n",
      "save best model to ./model/BCP/LA_BCP_8_labeled/pre_train/iter_20_dice_0.0731.pth\n",
      "save best model to ./model/BCP/LA_BCP_8_labeled/pre_train/iter_20_dice_0.0731.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|      | 9/11 [00:45<00:10,  5.05s/it]\n"
     ]
    }
   ],
   "source": [
    "if args.deterministic:\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "\n",
    "patch_size = (112, 112, 80)\n",
    "num_classes = 2\n",
    "## make logger file\n",
    "pre_snapshot_path = \"./model/BCP/LA_{}_{}_labeled/pre_train\".format(args.exp, args.labelnum)\n",
    "self_snapshot_path = \"./model/BCP/LA_{}_{}_labeled/self_train\".format(args.exp, args.labelnum)\n",
    "print(\"Starting BCP training.\")\n",
    "for snapshot_path in [pre_snapshot_path, self_snapshot_path]:\n",
    "    if not os.path.exists(snapshot_path):\n",
    "        os.makedirs(snapshot_path)\n",
    "# -- Pre-Training\n",
    "logging.basicConfig(filename=pre_snapshot_path+\"/log.txt\", level=logging.INFO, format='[%(asctime)s.%(msecs)03d] %(message)s', datefmt='%H:%M:%S')\n",
    "logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))\n",
    "logging.info(str(args))\n",
    "pre_train(args, pre_snapshot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.params object at 0x7fa3f3728fb0>\n",
      "<__main__.params object at 0x7fa3f3728fb0>\n",
      "<__main__.params object at 0x7fa3f3728fb0>\n",
      "<__main__.params object at 0x7fa3f3728fb0>\n",
      "<__main__.params object at 0x7fa3f3728fb0>\n",
      "Mode = train, total samples: 80\n",
      "2 iterations per epoch\n",
      "2 iterations per epoch\n",
      "2 iterations per epoch\n",
      "2 iterations per epoch\n",
      "2 iterations per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10123/98327308.py:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(str(path))\n",
      "  0%|                                           | 0/6 [00:00<?, ?it/s]/tmp/ipykernel_10123/98327308.py:21: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  return torch.Tensor(batch_list).cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 : loss: 1.385639, loss_l: 0.686397, loss_u: 0.699241\n",
      "iteration 1 : loss: 1.385639, loss_l: 0.686397, loss_u: 0.699241\n",
      "iteration 1 : loss: 1.385639, loss_l: 0.686397, loss_u: 0.699241\n",
      "iteration 1 : loss: 1.385639, loss_l: 0.686397, loss_u: 0.699241\n",
      "iteration 1 : loss: 1.385639, loss_l: 0.686397, loss_u: 0.699241\n",
      "iteration 2 : loss: 1.297386, loss_l: 0.635858, loss_u: 0.661528\n",
      "iteration 2 : loss: 1.297386, loss_l: 0.635858, loss_u: 0.661528\n",
      "iteration 2 : loss: 1.297386, loss_l: 0.635858, loss_u: 0.661528\n",
      "iteration 2 : loss: 1.297386, loss_l: 0.635858, loss_u: 0.661528\n",
      "iteration 2 : loss: 1.297386, loss_l: 0.635858, loss_u: 0.661528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|                             | 1/6 [00:04<00:21,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 3 : loss: 1.383565, loss_l: 0.639192, loss_u: 0.744373\n",
      "iteration 3 : loss: 1.383565, loss_l: 0.639192, loss_u: 0.744373\n",
      "iteration 3 : loss: 1.383565, loss_l: 0.639192, loss_u: 0.744373\n",
      "iteration 3 : loss: 1.383565, loss_l: 0.639192, loss_u: 0.744373\n",
      "iteration 3 : loss: 1.383565, loss_l: 0.639192, loss_u: 0.744373\n",
      "iteration 4 : loss: 1.326058, loss_l: 0.634418, loss_u: 0.691640\n",
      "iteration 4 : loss: 1.326058, loss_l: 0.634418, loss_u: 0.691640\n",
      "iteration 4 : loss: 1.326058, loss_l: 0.634418, loss_u: 0.691640\n",
      "iteration 4 : loss: 1.326058, loss_l: 0.634418, loss_u: 0.691640\n",
      "iteration 4 : loss: 1.326058, loss_l: 0.634418, loss_u: 0.691640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|                       | 2/6 [00:07<00:14,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 5 : loss: 1.346827, loss_l: 0.596793, loss_u: 0.750033\n",
      "iteration 5 : loss: 1.346827, loss_l: 0.596793, loss_u: 0.750033\n",
      "iteration 5 : loss: 1.346827, loss_l: 0.596793, loss_u: 0.750033\n",
      "iteration 5 : loss: 1.346827, loss_l: 0.596793, loss_u: 0.750033\n",
      "iteration 5 : loss: 1.346827, loss_l: 0.596793, loss_u: 0.750033\n",
      "iteration 6 : loss: 1.242440, loss_l: 0.624348, loss_u: 0.618091\n",
      "iteration 6 : loss: 1.242440, loss_l: 0.624348, loss_u: 0.618091\n",
      "iteration 6 : loss: 1.242440, loss_l: 0.624348, loss_u: 0.618091\n",
      "iteration 6 : loss: 1.242440, loss_l: 0.624348, loss_u: 0.618091\n",
      "iteration 6 : loss: 1.242440, loss_l: 0.624348, loss_u: 0.618091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|                 | 3/6 [00:10<00:09,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 7 : loss: 1.395901, loss_l: 0.677066, loss_u: 0.718835\n",
      "iteration 7 : loss: 1.395901, loss_l: 0.677066, loss_u: 0.718835\n",
      "iteration 7 : loss: 1.395901, loss_l: 0.677066, loss_u: 0.718835\n",
      "iteration 7 : loss: 1.395901, loss_l: 0.677066, loss_u: 0.718835\n",
      "iteration 7 : loss: 1.395901, loss_l: 0.677066, loss_u: 0.718835\n",
      "iteration 8 : loss: 1.320524, loss_l: 0.648389, loss_u: 0.672135\n",
      "iteration 8 : loss: 1.320524, loss_l: 0.648389, loss_u: 0.672135\n",
      "iteration 8 : loss: 1.320524, loss_l: 0.648389, loss_u: 0.672135\n",
      "iteration 8 : loss: 1.320524, loss_l: 0.648389, loss_u: 0.672135\n",
      "iteration 8 : loss: 1.320524, loss_l: 0.648389, loss_u: 0.672135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|           | 4/6 [00:13<00:06,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 9 : loss: 1.213508, loss_l: 0.614705, loss_u: 0.598802\n",
      "iteration 9 : loss: 1.213508, loss_l: 0.614705, loss_u: 0.598802\n",
      "iteration 9 : loss: 1.213508, loss_l: 0.614705, loss_u: 0.598802\n",
      "iteration 9 : loss: 1.213508, loss_l: 0.614705, loss_u: 0.598802\n",
      "iteration 9 : loss: 1.213508, loss_l: 0.614705, loss_u: 0.598802\n",
      "iteration 10 : loss: 1.365941, loss_l: 0.709458, loss_u: 0.656484\n",
      "iteration 10 : loss: 1.365941, loss_l: 0.709458, loss_u: 0.656484\n",
      "iteration 10 : loss: 1.365941, loss_l: 0.709458, loss_u: 0.656484\n",
      "iteration 10 : loss: 1.365941, loss_l: 0.709458, loss_u: 0.656484\n",
      "iteration 10 : loss: 1.365941, loss_l: 0.709458, loss_u: 0.656484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|           | 4/6 [00:16<00:08,  4.14s/it]\n"
     ]
    }
   ],
   "source": [
    "# -- Self-training\n",
    "logging.basicConfig(filename=self_snapshot_path+\"/log.txt\", level=logging.INFO, format='[%(asctime)s.%(msecs)03d] %(message)s', datefmt='%H:%M:%S')\n",
    "logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))\n",
    "logging.info(str(args))\n",
    "self_train(args, pre_snapshot_path, self_snapshot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6295057,
     "sourceId": 10189147,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
